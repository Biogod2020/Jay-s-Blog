<div class="ltx_page_content">
    <div class="package-alerts ltx_document" role="status" aria-label="Conversion errors have been found">
        <button aria-label="Dismiss alert" onclick="closePopup()">
            <span aria-hidden="true"><svg role="presentation" width="20" height="20" viewBox="0 0 44 44"
                    aria-hidden="true" focusable="false">
                    <path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
                    <path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
                </svg></span>
        </button>
        <p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html"
                target="_blank">sometimes display errors</a> due to content that did not convert correctly from the
            source. This paper uses the following packages that are not yet supported by the HTML conversion tool.
            Feedback on these issues are not necessary; they are known and are being worked on.</p>
        <ul arial-label="Unsupported packages used in this paper">
            <li>failed: dm.cls</li>
            <li>failed: datetime.sty</li>
            <li>failed: mdframed.sty</li>
        </ul>
        <p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a
                href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.
        </p>
    </div>
    <div id="target-section" class="section"><a id="license-tr"
            href="https://info.arxiv.org/help/license/index.html#licenses-available">License: CC BY 4.0</a>
        <div id="watermark-tr">arXiv:2511.17652v1 [q-bio.QM] 20 Nov 2025</div>
    </div>
    <article class="ltx_document ltx_authors_1line">
        <div class="ltx_para" id="p1">
            <span class="ltx_ERROR undefined">\svgsetup</span>
            <p class="ltx_p">inkscapelatex=false<span class="ltx_ERROR undefined">\pdftrailerid</span>redacted</p>
            <button class="sr-only button" style="display: none;">Report issue for preceding element</button>
        </div>
        <h1 class="ltx_title ltx_title_document" lang="en">TeamPath: Building MultiModal Pathology Experts with
            Reasoning AI Copilots</h1><button class="sr-only button" style="display: none;">Report issue for preceding
            element</button>
        <div class="ltx_authors">
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Tianyu Liu
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Interdepartmental Program of Computational
                        Biology and Biomedical Informatics, Yale University
                    </span>
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Department of Biostatistics, Yale
                        University
                    </span>
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Broad Institute of MIT and Harvard
                    </span>
                    <span class="ltx_contact ltx_role_affiliation" lang="en">These authors contributed equally to this
                        work as leading authors.
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Weihao Xuan
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Department of Complexity Science and
                        Engineering, The University of Tokyo
                    </span>
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Center for Advanced Intelligence Project,
                        RIKEN
                    </span>
                    <span class="ltx_contact ltx_role_affiliation" lang="en">These authors contributed equally to this
                        work as leading authors.
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Hao Wu
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Department of Pathology, Yale University
                    </span>
                    <span class="ltx_contact ltx_role_affiliation" lang="en">These authors contribute equally to this
                        project as human experts
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Peter Humphrey
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Department of Pathology, Yale University
                    </span>
                    <span class="ltx_contact ltx_role_affiliation" lang="en">These authors contribute equally to this
                        project as human experts
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Marcello DiStasio
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Department of Pathology, Yale University
                    </span>
                    <span class="ltx_contact ltx_role_affiliation" lang="en">These authors contribute equally to this
                        project as human experts
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Heli Qi
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Center for Advanced Intelligence Project,
                        RIKEN
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Rui Yang
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Center for Quantitative Medicine, Duke-NUS
                        Medical School
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Simeng Han
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Department of Computer Science, Yale
                        University
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Tinglin Huang
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Department of Computer Science, Yale
                        University
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Fang Wu
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Department of Computer Science, Stanford
                        University
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Nan Liu
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Center for Quantitative Medicine, Duke-NUS
                        Medical School
                    </span>
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Pre-hospital &amp; Emergency Research
                        Center, Duke-NUS Medical School
                    </span>
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Department of Biostatistics and
                        Bioinformatics, Duke University
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Irene Li
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">The Graduate School of Engineering, The
                        University of Tokyo
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Hua Xu
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Interdepartmental Program of Computational
                        Biology and Biomedical Informatics, Yale University
                    </span>
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Department of Biomedical Informatics and
                        Data Science, Yale University
                    </span></span></span>
            <span class="ltx_creator ltx_role_author">
                <span class="ltx_personname" lang="en">Hongyu Zhao
                </span><span class="ltx_author_notes">
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Interdepartmental Program of Computational
                        Biology and Biomedical Informatics, Yale University
                    </span>
                    <span class="ltx_contact ltx_role_affiliation" lang="en">Department of Biostatistics, Yale
                        University
                    </span></span></span>
        </div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
        <div class="ltx_abstract" id="abstract">
            <h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button"
                style="display: none;">Report issue for preceding element</button>
            <p class="ltx_p"><span class="ltx_text" lang="en">Advances in AI have introduced several strong models in
                    computational pathology to usher it into the era of multi-modal diagnosis, analysis, and
                    interpretation. However, the current pathology-specific visual language models still lack capacities
                    in making diagnosis with rigorous reasoning paths as well as handling divergent tasks, and thus
                    challenges of building AI Copilots for real scenarios still exist. Here we introduce TeamPath, an AI
                    system powered by reinforcement learning and router-enhanced solutions based on large-scale
                    histopathology multimodal datasets, to work as a virtual assistant for expert-level disease
                    diagnosis, patch-level information summarization, and cross-modality generation to integrate
                    transcriptomic information for the clinical usage. We also collaborate with pathologists from Yale
                    School of Medicine to demonstrate that TeamPath can assist them in working more efficiently by
                    identifying and correcting expert conclusions and reasoning paths. Overall, TeamPath can flexibly
                    choose the best settings according to the needs, and serve as an innovative and reliable system for
                    information communication across different modalities and experts.</span></p><button
                class="sr-only button" style="display: none;">Report issue for preceding element</button>
        </div>
        <div class="ltx_classification">
            <h6 class="ltx_title ltx_title_classification">keywords: </h6><button class="sr-only button"
                style="display: none;">Report issue for preceding element</button>
            <span class="ltx_text" lang="en">Histopathology Analysis, Pathology Foundation Model, Cancer Diagnosis,
                Large Language Model, Visual Language Model, Large Reasoning Model</span>
        </div>
        <section class="ltx_section" id="S1" lang="en">
            <h2 class="ltx_title ltx_title_section">
                <span class="ltx_tag ltx_tag_section">1 </span>Introduction
            </h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S1.p1">
                <p class="ltx_p">Pathological diagnosis is a complex yet essential component of clinical
                    decision-making. Through the examination of whole-slide images (WSIs), physicians assess disease
                    severity, evaluate the spatial distribution of malignant and healthy cells, and generate diagnostic
                    reports or treatment recommendations <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">song2023artificial</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">bera2019artificial</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">niazi2019digital</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">al2012digital</span>)</cite>. However,
                    this process is both time-intensive and labor-intensive, and its accuracy can be influenced by
                    uncontrollable factors such as the physician’s workload, fatigue, and level of expertise <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2024challenges</span>)</cite>. Recent
                    advances in Artificial Intelligence (AI) have demonstrated considerable promise in augmenting
                    diagnostic workflows <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">chen2024towards</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">lu2023towards</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">xu2024whole</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">ma2024generalizablepathologyfoundationmodel</span>,
                        <span class="ltx_ref ltx_missing_citation ltx_ref_self">Rannikko2025</span>)</cite>. In
                    particular, the deployment of foundation models for pathology not only reduces resource demands but
                    also enables scalable, reproducible analysis. A deeper understanding of how these models generate
                    diagnostic predictions, together with continued efforts to improve their mechanisms, is crucial for
                    enhancing reliability and precision in clinical applications. This represents an emerging and
                    important direction for future research.</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S1.p2">
                <p class="ltx_p">Deconstructing the diagnostic workflow of pathologists provides critical insights into
                    the role of AI in this domain. In practice, physicians analyze WSIs or regions of interest (ROIs) by
                    examining selected patches, which might contain diagnostically relevant features. Localized
                    assessments are then aggregated into a diagnostic report, which can support higher-level clinical
                    investigations <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">tran2025generating</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">liu2025spemo</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">shaikovski2025prism2</span>)</cite> when
                    paired with the corresponding ROIs. Meanwhile, visual–language models (VLMs) <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2024vision</span>)</cite> process
                    paired image–text inputs, typically images with accompanying questions or instructions, and generate
                    responses by integrating and aligning information across modalities. Inspired by this parallel,
                    researchers have begun to develop VLMs specifically tailored for WSIs and pathology diagnosis. For
                    instance, SlideChat <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">Chen_2025_CVPR</span>)</cite> and PathChat
                    <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">lu2024multimodal</span>)</cite> were
                    designed as copilots for pathology interpretation, while HistoGPT <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">tran2025generating</span>)</cite> can
                    generate medical reports directly from histopathology images. Similarly, spEMO <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">liu2025spemo</span>)</cite> extends this
                    capability by incorporating both molecular and pathological information for a stronger report
                    generation capacity. Other pathology foundation models (PFMs), such as MUSK <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">xiang2025vision</span>)</cite> and PLIP
                    <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">huang2023visual</span>)</cite>, leverage
                    text–image alignment to improve embedding quality. Collectively, these domain-specific PFMs and VLMs
                    have advanced applications in medical report generation and multimodal integration, establishing
                    pathology-focused VLMs as a promising and rapidly progressing research direction.</p><button
                    class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S1.p3">
                <p class="ltx_p">Nevertheless, certain tasks in pathology diagnosis are inherently complex and require
                    deliberate reasoning before actions can be taken. To address such challenges, foundation models must
                    demonstrate robust reasoning capabilities. Conventional VLMs, however, often struggle with
                    reasoning-oriented questions, even when trained on extensive datasets. Equipping VLMs with effective
                    reasoning capacity thus remains a central challenge in the medical domain. At the same time,
                    physicians play an indispensable role in the era of medical AI. They are not only domain experts but
                    also important users and researchers for helping us correct errors made by AI models or interact
                    with models to improve each other’s performances. Consequently, developing effective strategies for
                    human–AI collaboration, particularly in ways that enhance rather than replace physician expertise,
                    is an urgent priority for advancing reliable and clinically meaningful solutions.</p><button
                    class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S1.p4">
                <p class="ltx_p">Fortunately, encouraging progress in reasoning has been achieved in other domains, such
                    as mathematics and logic, through the training of large language models (LLMs, which are text-only)
                    and VLMs. These advances are largely driven by reinforcement learning (RL) with/without
                    chain-of-thought (CoT) supervision, which has demonstrated strong reasoning capabilities <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">chu2025sft</span>)</cite>. Importantly,
                    such techniques can be adapted to medical applications, provided that domain-appropriate datasets
                    are carefully constructed. Within pathology, several groups have begun to explore reasoning-oriented
                    models for diagnostic tasks <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2025patho</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">xu2025discovering</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">wu2025pathvlm</span>)</cite>. However,
                    current approaches tend to be technically homogeneous and insufficient to disentangle the
                    contribution of the reasoning process from the final answer. Little attention has been given to
                    analyzing errors produced by reasoning, which is critical for improving model reliability. Moreover,
                    most existing models remain closed-source, which limit opportunities for rigorous evaluation in
                    real-world clinical scenarios and hindering community-driven progress. To address these gaps, we aim
                    to develop a high-precision reasoning model that not only generates accurate diagnostic predictions
                    but also explicates its reasoning path. Such a model would serve as a trustworthy assistant to
                    physicians, support more informed clinical decision-making, and ultimately contribute to alleviating
                    patient burden while advancing the goals of precision medicine.</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S1.p5">
                <p class="ltx_p">In this manuscript, we present TeamPath, a framework that augments VLMs with
                    multi-modal reasoning and a task-sensitive routing mechanism, enabling robust performance in several
                    pathology-related tasks. Our approach begins with the careful selection of base models and the
                    design of medical-specific prompts to curate high-quality, reasoning-enriched training data. Through
                    comprehensive analyses, we demonstrate both the necessity of equipping VLMs with reasoning
                    capabilities to address complex pathology tasks and the importance of constructing high-quality
                    datasets for model success. We further showcase the effectiveness of TeamPath across diverse
                    downstream applications, including multi-modal pathology visual question answering (Pathology VQA)
                    and caption summarization. By leveraging an LLM-driven router, TeamPath dynamically selects the most
                    suitable strategy to meet task requirements, functioning as a reliable and adaptive system.
                    Importantly, we invite pathologists to evaluate the model’s reasoning pathways, thereby validating
                    its practical utility as a medical assistant. Finally, we introduce a new task, known as spatial
                    transcriptomic profiles generation, to assess the cross-modality generative ability of TeamPath.
                    Overall, TeamPath provides a new avenue for integrative analyses that combine molecular and
                    histopathological signatures.

                </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
        </section>
        <section class="ltx_section" id="S2" lang="en">
            <h2 class="ltx_title ltx_title_section">
                <span class="ltx_tag ltx_tag_section">2 </span>Results
            </h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S2.p1">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">Dataset and Method Overview.</span> The curation
                    of high-quality datasets is increasingly critical for advancing PFMs and VLMs, particularly in the
                    era of multimodal reasoning and summarization. At the same time, careful attention must be paid to
                    preventing data leakage to ensure unbiased evaluation of model performance. To this end, and
                    leveraging prior data collection strategies, we distilled a subset of data from PathGen-1.6M <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">sunpathgen</span>)</cite>, which is a
                    large-scale resource comprising nearly 10,000 WSIs and 1.6 million ROIs derived from TCGA data <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">weinstein2013cancer</span>)</cite>, for
                    the usage in the finetuning stage with reinforcement learning. Reasoning data were constructed using
                    COT templates generated based on the advanced reasoning model o4-mini <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">oai4mini</span>)</cite>, with subsequent
                    quality validation performed by pathologists at Yale School of Medicine. Importantly, this dataset
                    does not overlap with the benchmark testing set used for Pathology VQA evaluation <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">he2020pathvqa</span>)</cite>, namely
                    PathMMU <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">sun2024pathmmu</span>)</cite>, which
                    contains ROIs paired with questions across five diagnostic categories and represents one of the most
                    advanced evaluation sources. In addition, another subset distilled from PathGen-1.6M was curated as
                    the testing dataset for the ROI summarization task. To assess performance in cross-modality
                    generation, we leveraged HEST-1K <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">jaume2024hest</span>)</cite> and
                    STImage1K4M <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">chen2024stimage</span>)</cite>, two
                    multi-omic histopathology collections to assess the prediction of transcriptomic profiles as
                    molecular signatures from ROIs. These two datasets are used to construct training, validation, and
                    test sets. The overall data preprocessing workflow and sample sizes are summarized in Extended Data
                    Figure <a class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#A4.F1"
                        title="Extended Data Fig. 1 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">1</span></a>.</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S2.p2">
                <p class="ltx_p">The overall process of dataset curation and model training is summarized in Figures <a
                        class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#S2.F1"
                        title="Figure 1 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">1</span></a> (a)-(d). TeamPath emerges as a robust multimodal
                    AI assistant for both disease diagnosis and modality generation. To refine its reasoning
                    capabilities, we employ Group Relative Policy Optimization (GRPO) <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">guo2025deepseek</span>)</cite> to finetune
                    the base model (the default setting is Patho-R1-7B), thereby enhancing its ability to perform
                    reasoning over pathology images. With this capacity for structured reasoning, TeamPath demonstrates
                    strong performance in addressing Pathology VQA tasks, as shown in our comprehensive benchmarking
                    analysis. Importantly, the model also maintains high performance on tasks where reasoning is less
                    critical, such as image summarization (known as caption generation) and cross-modality generation.
                    This adaptability enables TeamPath to support task-specific optimization through either
                    reinforcement learning or supervised finetuning. In collaboration with expert pathologists, we
                    further demonstrate that TeamPath can function as a clinical copilot, assisting in applications such
                    as correcting inaccurate conclusions and identifying flawed reasoning paths. Taken together,
                    TeamPath advances both biomedical research and clinical practice in histopathology analysis.
                    Finally, a comparative summary of task- and metric-specific rankings, shown in Figure <a
                        class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#S2.F1"
                        title="Figure 1 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">1</span></a> (e), demonstrates the superior performance of
                    TeamPath across multiple dimensions.</p><button class="sr-only button" style="display: none;">Report
                    issue for preceding element</button>
            </div>
            <figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_square" height="855" id="S2.F1.g1" src="x1.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1:
                    </span>Landscape of TeamPath (a) Steps of dataset curation. We extract image-text pairs from a
                    processed TCGA dataset (PathGen-1.6M). (b) Word cloud visualization of ROI captions (upper) and
                    questions (bottom). (c) The core visual language model architecture of TeamPath. (d) TeamPath as a
                    system with an LLM-enhanced router (with over 80% accuracy in choosing the correct approach) and the
                    corresponding capacities in various downstream applications. The logo fire means that we need to
                    adjust the parameters of models, and the logo snowflake means that we do not change the parameters.
                    (e) Overall ranking list of different methods across tasks and metrics. A lower rank (larger bubble)
                    means a better method.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S2.p3">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">TeamPath improves the performance of ROI-level
                        assessment with reasoning ability.</span> The increasing complexity of histopathology image
                    analysis presents significant challenges for developing expert-level VLMs. One particularly
                    demanding setting is Pathology VQA, which requires models to correctly respond to questions grounded
                    in histopathology images. Unlike traditional classification tasks (e.g., disease-state
                    classification or cancer cell identification), Pathology VQA involves a broader and more complex
                    range of scenarios <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">he2020pathological</span>)</cite> and
                    demands higher accuracy in answer production. To evaluate model performances under this setting, we
                    employ the recently published PathMMU dataset, which includes VQA pairs spanning five categories,
                    ranging from expert-annotated questions to images from social media. Importantly, PathMMU is
                    excluded from the training data of all evaluated models to ensure fairness. Reflecting the
                    real-world requirements faced by pathologists, we emphasize the need for high-quality, fine-grained
                    answers that integrate multimodal information and contribute meaningfully at the clinical level. Our
                    baseline comparisons encompass (1) general-domain VLMs, including Qwen2.5VL-3B, Qwen2.5VL-7B <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">team2024qwen2</span>)</cite>, and
                    InternVL3-8B <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2025internvl3</span>)</cite>; (2)
                    medical-domain VLMs, including MedGemma-4B <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">sellergren2025medgemma</span>)</cite> and
                    MedVLThinker-7B <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">huang2025medvlthinker</span>)</cite>; (3)
                    pathology-specific VLMs, including PathGen-LLaVA-13B <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">sunpathgen</span>)</cite> and Patho-R1-7B
                    <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2025patho</span>)</cite>; and (4) a
                    random-answer baseline. Model performance is assessed by computing accuracy relative to
                    expert-generated answers within PathMMU, enabling a rigorous and fair benchmarking analysis.</p>
                <button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S2.p4">
                <p class="ltx_p">Figures <a class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#S2.F2"
                        title="Figure 2 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">2</span></a> (a)-(c) show our benchmarking results across
                    different categories, including PubMed, SocialPath, Atlas, EduContent, and PathCLS. PathMMU also
                    pre-defines different sample types, and “overall" represents all testing samples in the selected
                    category, “tiny_test" represents testing samples used for expert evaluation, and “test” represents
                    the rest of the samples. We find that TeamPath outperforms all other baseline models, including
                    domain-expert VLMs with similar or larger parameter size, such as Patho-R1-7B and PathGen-LLaVA-13B,
                    in nearly all evaluations. Both general VLMs and medical VLMs performed poorly in this task. We
                    further visualize the comprehensive benchmarking analysis, including ranking and accuracy of each
                    method with all samples in Figure <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#S2.F2"
                        title="Figure 2 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">2</span></a> (d), which shows that TeamPath also has the lowest
                    rank by considering all categories jointly. Therefore, our experiment results show that introducing
                    reasoning capacities to build pathology-expert VLMs can enhance their ability in making diagnoses,
                    and thus TeamPath can serve as a strong performer for the key feature identification and content
                    understanding of ROIs.
                </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S2.p5">
                <p class="ltx_p">To obtain a more intuitive understanding of the key contributions of TeamPath following
                    reinforcement learning training, we selected two case studies where TeamPath provided the correct
                    answer while other models failed to make accurate judgments.
                </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S2.p6">
                <p class="ltx_p">Figure <a class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#S2.F3"
                        title="Figure 3 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">3</span></a> highlights the importance of precise morphological
                    criteria in recognizing lipoblasts. While several models incorrectly selected option C, describing
                    large, clear vacuoles displacing the nucleus to the periphery, a hallmark of mature adipocytes. We
                    found that TeamPath correctly identified option B as the defining feature of lipoblasts <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">hisaoka2014lipoblast</span>)</cite>.
                    Lipoblasts are diagnostically recognized by the presence of moderately sized cytoplasmic fat
                    vacuoles that indent or scallop the nucleus, a distinction that separates them from both mature
                    adipocytes and other stromal features. By emphasizing nuclear indentation rather than displacement,
                    TeamPath demonstrated accurate pathological reasoning aligned with standard diagnostic criteria.
                    This correctness not only underscores the reliability of TeamPath in differentiating subtle
                    histologic features but also highlights the critical nuance needed in distinguishing malignant
                    lipoblastic cells from benign adipocytic processes. Moreover, Extended Data Figure <a
                        class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#A4.F2"
                        title="Extended Data Fig. 2 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">2</span></a> demonstrates that TeamPath correctly identified
                    synaptophysin as the targeted marker in the immunohistochemical stain of section A. The brown,
                    cytoplasmic staining pattern observed is a hallmark of synaptophysin, which is widely used as a
                    marker of neuroendocrine differentiation. While other models misclassified the stain as estrogen
                    receptor or S100 protein, TeamPath distinguished the subtle morphological and staining features that
                    separate synaptophysin from nuclear markers like estrogen receptor or more diffuse proteins such as
                    S100. This highlights both the accuracy and interpretive strength of TeamPath in
                    immunohistochemistry tasks, particularly in recognizing marker-specific staining patterns and
                    avoiding common pitfalls that lead to misclassification. We also note that previous pathology expert
                    models have obvious shortcomings, such as Patho-R1-7B’s garbled output and PathGen-LLaVA’s lack of
                    interpretable diagnostic outputs. Instead, TeamPath can make correct identification supported by
                    comprehensive explanations, explained in the information provided by the reasoning paths.
                </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S2.p7">
                <p class="ltx_p">We also explored the contributions of different training strategies and highlighted the
                    importance of selecting base models based on a set of ablation studies, discussed in Appendix <a
                        class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#A2"
                        title="Appendix B SFT vs RL: Comparison for training strategies. ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">B</span></a> and Extended Data Figures <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#A4.F3"
                        title="Extended Data Fig. 3 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">3</span></a> (a)-(d), as well as in Appendix <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#A3"
                        title="Appendix C Studies for training data ablation. ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">C</span></a> and Extended Data Figure <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#A4.F4"
                        title="Extended Data Fig. 4 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">4</span></a> for the data ablation study.</p><button
                    class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="S2.F2.g1" src="x2.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2:
                    </span>Benchmarking results with PathMMU for the pathology VQA task. We note that since we did not
                    have information about the testing setting of PathGene-LLaVA-13B, we used results reported by the
                    model creators in <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">sunpathgen</span>)</cite>. (a) Accuracy
                    across different categories of all selected methods with all samples. (b) Accuracy across different
                    categories of all selected methods with samples from a tiny set. (c) Accuracy across different
                    categories of all selected methods with samples from a large set. (d) Joint visualization with
                    accuracy and ranking information for all selected methods. The darker the bubble color, the higher
                    the model score; The larger the bubble shape, the lower the model ranking.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <figure class="ltx_figure" id="S2.F3"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_square" height="828" id="S2.F3.g1" src="x3.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Case
                    study (topic: synaptophysin, which is a precursor cell that develops into an adipocyte (fat cell))
                    based on the outputs from different models. We highlight the correct information with green text and
                    incorrect information with red text. For the models with errors, we consider two cases. The first
                    case is a wrong answer, and the second case is a confused reasoning path.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S2.p8">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">TeamPath acts as a Copilot in the pathologists-AI
                        collaboration system.</span> Beyond demonstrating the capacity of TeamPath in handling VQA sets
                    as a pathology expert, we further explore its potential as an AI-assisted collaborator <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">mialon2023gaia</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">liu2025towards</span>)</cite>. An
                    effective copilot should not only provide accurate responses to user queries but also reduce the
                    effort required to resolve them, thereby saving both time and cost. To this end, we designed an
                    algorithm in TeamPath with test-time scaling (TTS) <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">snell2024scaling</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">liu2025towards</span>)</cite> and engaged
                    expert pathologists from Yale School of Medicine (YSM) to collaborate with TeamPath in analyzing
                    histopathology images and generating answers on demand. Specifically, we randomly subsampled 10
                    question–image pairs from each category within the PathMMU “tiny_test” set and examined two
                    capacities: (1) the ability of TeamPath to act as an auto-verifier or auto-corrector for incorrect
                    expert assessments, and (2) the ability of TeamPath to revise and correct reasoning pathways when
                    human experts fail to provide accurate answers. The overall paradigm for these two tasks is
                    summarized in Figure <a class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#S2.F4"
                        title="Figure 4 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">4</span></a> (a). Through this study, we aim to establish
                    future paradigms of human–AI collaboration in biomedical research and clinical practice,
                    highlighting the role of TeamPath as a reliable and strong copilot.</p><button
                    class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S2.p9">
                <p class="ltx_p">We jointly compared the expert-provided results with those corrected by TeamPath and
                    visualized the corresponding accuracies in Figure <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#S2.F4"
                        title="Figure 4 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">4</span></a> (b). Our analysis shows that TeamPath
                    significantly improves accuracy across all PathVQA categories (p-value = 0.004), demonstrating that
                    its corrective contribution is consistent and robust regardless of the source of pathology ROIs or
                    questions. Notably, even in categories where expert performance is relatively low, such as PubMed,
                    TeamPath achieves substantial gains. These improvements demonstrate the effectiveness of TeamPath as
                    a corrector, as reflected by the observed accuracy differences. To further illustrate this
                    capability, we conducted a case study (Figure <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#S2.F4"
                        title="Figure 4 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">4</span></a> (c)) in which the expert provided an incorrect
                    answer, whereas TeamPath generated the correct response with an improved reasoning path. In this
                    example, the task involved identifying characteristic nuclear features within the image. The
                    expert’s reasoning correctly accounted for cell size but overlooked nucleolar details, leading to an
                    erroneous conclusion. In contrast, TeamPath integrated multiple features, including nuclear size,
                    shape, staining depth, and prior knowledge of the cancer cell line, to eliminate incorrect options
                    and arrive at the correct decision. Moreover, TeamPath was also able to revise flawed reasoning
                    paths when experts could not provide an answer (e.g., “I do not know"), as shown in Extended Data
                    Figure <a class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#A4.F5"
                        title="Extended Data Fig. 5 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">5</span></a>. In summary, through collaborative evaluation with
                    pathologists, we demonstrate the capacity of TeamPath to not only fix erroneous answers but also
                    provide explicit reasoning steps, thereby enhancing both the transparency and interpretability of
                    model-assisted pathology diagnosis.</p><button class="sr-only button" style="display: none;">Report
                    issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S2.p10">
                <p class="ltx_p">We have also performed ablation studies for the verifier with three different choices
                    (using the corrector, o3 <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">oai4mini</span>)</cite>, and o4-mini).
                    Extended Data Figure <a class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#A4.F6"
                        title="Extended Data Fig. 6 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">6</span></a> shows that using o4-mini can achieve the best
                    performance on average, while it can also reduce the cost compared with using o3 or a more advanced
                    model, and thus o4-mini is selected here to perform verification.</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <figure class="ltx_figure" id="S2.F4"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_landscape" height="442" id="S2.F4.g1" src="x4.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4:
                    </span>Results of using TeamPath as the answer corrector/reason corrector. TeamPath can work with
                    pathologists together to improve the diagnosis accuracy and provide explainable reasons to support
                    the decision. (a) The illustration of self-verification/correction steps for both answers and
                    reasoning paths. (b) Accuracy before and after correction based on selected samples from PathMMU. We
                    report the average scores and standard deviation across three experts. The test is a one-sided
                    Wilcoxon Rank-sum test. (c) A case study to demonstrate the power of TeamPath as an AI assistant.
                </figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S2.p11">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">TeamPath performs better in summarizing the key
                        information from histopathology images.</span> In practical applications, pathology image
                    analysis often extends beyond generating correct answers and reasoning steps to encompass the
                    extraction of important image features for macroscopic or high-level descriptions. To evaluate this
                    capability, we designed experiments aimed at summarizing histopathology information from different
                    ROIs, thereby assessing the capacity of TeamPath to capture and convey high-level image content. For
                    this purpose, we constructed a testing dataset by subsampling 3,000 images and their corresponding
                    captions from PathGen-1.6M, with image categories defined using GPT-4o prompts <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">openai2023gpt4</span>)</cite>. These
                    captions were further annotated to include tissue- and disease-state information. To support
                    training, we curated a separate dataset of 50,000 images, ensuring no overlap with the testing set.
                    For benchmarking, we employed the same set of baseline models used in the Pathology VQA experiments.
                    Model performance was evaluated using multiple similarity metrics between generated summaries and
                    reference captions, including BLEU <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">papineni2002bleu</span>)</cite>,
                    ROUGE-1/2/L <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">lin2004rouge</span>)</cite>, BERTScore
                    <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">zhangbertscore</span>)</cite>, and MEDCON
                    <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">soldaini2016quickumls</span>)</cite>. All
                    metrics were scaled to a 0–100 range, with higher values indicating better performance.</p><button
                    class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S2.p12">
                <p class="ltx_p">Figure <a class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#S2.F5"
                        title="Figure 5 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">5</span></a> (a) compares the performance of TeamPath with
                    other VLMs across all selected metrics on the testing set. TeamPath consistently outperforms the
                    baselines across every metric, demonstrating its strength in generating summaries that align closely
                    with reference annotations in both content and structure. To provide a holistic assessment, we
                    further visualized the aggregated rankings and average scores of all methods in Figure <a
                        class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#S2.F5"
                        title="Figure 5 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">5</span></a> (b), which highlights the leading performance of
                    TeamPath across the joint set of evaluation metrics. Recognizing that performance may vary by sample
                    source, we also examined model performance across specific tissue and disease contexts. Figure <a
                        class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#S2.F5"
                        title="Figure 5 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">5</span></a> (c) reports ROUGE-L and BERT scores for samples
                    from patients with adenocarcinoma, while Figure <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#S2.F5"
                        title="Figure 5 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">5</span></a> (d) shows results for breast tissue samples. In
                    both cases, TeamPath maintains superior performance compared with competing baselines. As an
                    illustrative case study, Figure <a class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#S2.F5"
                        title="Figure 5 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">5</span></a> (e) presents an example output from TeamPath,
                    which accurately captures key organizational and pathological features—such as elongated
                    spindle-shaped cells with eosinophilic cytoplasm and elongated nuclei, characteristic of smooth
                    muscle cells. By contrast, outputs from baseline models (Extended Data Figure <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#A4.F7"
                        title="Extended Data Fig. 7 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">7</span></a>) contain less precise descriptions and, in some
                    cases, incorrect content, further underscoring the advantages of TeamPath in summarization tasks.
                </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S2.p13">
                <p class="ltx_p">Therefore, we conclude that TeamPath demonstrates as a strong performer in providing
                    the high-level interpretations with pathology features of assigned ROIs.</p><button
                    class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <figure class="ltx_figure" id="S2.F5"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_portrait" height="962" id="S2.F5.g1" src="x5.png"
                    width="705">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5:
                    </span>Benchmarking results of the caption summary task. (a) Performances of different methods for
                    summarizing the caption based on ROI-level information across all metrics. We report the average
                    scores and scaled standard deviation (0.1*sd) with all samples in the testing set. (b) Joint
                    visualization with metric scores and ranking information for all selected methods. The darker the
                    bubble color, the higher the model score; The larger the bubble shape, the lower the model ranking.
                    (c) ROUGE-L and BERT scores based on samples from the selected disease across all methods. (d)
                    ROUGE-L and BERT scores based on samples from the selected tissue across all methods. (e) A case
                    study of caption summary generation based on TeamPath.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S2.p14">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">TeamPath introduces new modalities with a
                        cross-modality generation pipeline.</span> Building on our previous research and the existing
                    literature, we observe that current histopathology image analyses primarily rely on textual and
                    visual interpretations. However, given the breadth of biological signatures that can contribute to
                    disease modeling and diagnosis, there is a clear opportunity to design new pipelines that integrate
                    molecular information with histopathology features. Such integration can enable the generation of
                    new modalities and provide deeper insights into cellular heterogeneity, lineage tracing, and disease
                    mechanisms <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">chen2025visual</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">song2024analysis</span>)</cite>.
                    Therefore, we finetune TeamPath using paired histopathology images and transcriptomic profiles
                    generated with the Visium technology <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">visiumtech</span>)</cite>, a platform for
                    spatial transcriptomics (ST). Each ST spot includes a histopathology image as background and a
                    corresponding gene expression profile. Inspired by Cell2Sentence <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">levine2024cell2sentence</span>)</cite> and
                    Loki <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">chen2025visual</span>)</cite>, we convert
                    gene expression profiles into ranked gene lists, ordering genes from highest to lowest expression.
                    The task is then to generate these “spot sentences” and map them back into the transcriptomic space.
                    For training and evaluation, we use two of the largest public datasets: HEST-1K (invasive ductal
                    carcinoma, IDC) and STImage1K4M (brain tissue). HEST-1K includes a broad range of cancer datasets,
                    whereas STimage1K4M contains samples from both disease and normal tissues, thereby enhancing the
                    modeling of ST data. Baseline models for this task include the same VLMs evaluated in the Pathology
                    VQA setting, supplemented with Cell2Sentence-1B. Performance is assessed using Spot-level Pearson
                    Correlation Coefficient (SPCC), Gene-level Pearson Correlation Coefficient (GPCC), and mean squared
                    error (MSE). For SPCC and GPCC, higher values indicate better performance, whereas lower MSE values
                    reflect higher accuracy.</p><button class="sr-only button" style="display: none;">Report issue for
                    preceding element</button>
            </div>
            <div class="ltx_para" id="S2.p15">
                <p class="ltx_p">Figures <a class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#S2.F6"
                        title="Figure 6 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">6</span></a> (a) and (b) demonstrate that TeamPath outperforms
                    all baseline methods when evaluated by both SPCC and MSE across datasets from different sources,
                    underscoring its ability to generate spot-level gene expression profiles that closely resemble
                    measured results. Extended Data Figures <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#A4.F8"
                        title="Extended Data Fig. 8 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">8</span></a> (a) and (b) further confirm TeamPath’s better
                    performance in GPCC, highlighting its capacity to preserve gene-level heterogeneity across spatial
                    spots. To examine the impact of base model selection on cross-modality generation, we finetuned
                    Qwen2.5VL-7B for the same task and compared it with TeamPath. As shown in Extended Data Figures <a
                        class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#A4.F8"
                        title="Extended Data Fig. 8 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">8</span></a> (c) and (d), TeamPath, which was built on a
                    pathology-knowledge-enhanced VLM, outperformed the finetuned Qwen-series model. We also emphasize
                    the importance of task-specific finetuning, supported by the clear performance gap between the
                    unadapted base model and TeamPath in generating high-quality expression profiles. UMAP
                    visualizations of the generated profiles (Figures <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#S2.F6"
                        title="Figure 6 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">6</span></a> (c) and (d)) show that outputs from TeamPath are
                    more structured and closely aligned with reference profiles compared to those from the base model.
                    This observation is further validated by cluster-level heatmaps of gene expression patterns in brain
                    (Figure <a class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#S2.F6"
                        title="Figure 6 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">6</span></a> (e)) and IDC (Figure <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#S2.F6"
                        title="Figure 6 ‣ 2 Results ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">6</span></a> (f)) datasets, where TeamPath more accurately
                    recapitulates the biological signal present in the ground truth data. Collectively, these findings
                    demonstrate that the effectiveness of TeamPath in cross-modality generation arises from both the
                    choice of a pathology-informed base model and targeted task-specific finetuning. With these
                    advantages, TeamPath represents a promising approach for generating in-silico or unseen expression
                    profiles directly from histopathology images, thereby providing molecular-level insights into
                    disease phenotypes.
                </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <figure class="ltx_figure" id="S2.F6"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_square" height="735" id="S2.F6.g1" src="x6.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6:
                    </span>Evaluation of model performances for transcriptomic profile generation. (a) SPCC (higher is
                    better) and MSE (lower is better) scores across different methods for the brain tissue. We report
                    the average scores and scaled standard deviation (0.1*sd) for better visualization. (b) SPCC and MSE
                    scores across different methods for the IDC samples. We report the average scores and scaled
                    standard deviation (0.1*sd) for better visualization. (c) UMAP visualization from the testing set of
                    brain to compare the generated results between Patho-R1 (base) and TeamPath colored by data sources.
                    (d) UMAP visualization from the testing set of IDC to compare the generated results between Patho-R1
                    (base) and TeamPath colored by data sources. (e) Comparison of expression profiles between generated
                    data and real data based on the brain tissue. (f) Comparison of expression profiles between
                    generated data and real data based on the IDC samples.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
        </section>
        <section class="ltx_section" id="S3" lang="en">
            <h2 class="ltx_title ltx_title_section">
                <span class="ltx_tag ltx_tag_section">3 </span>Discussion
            </h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S3.p1">
                <p class="ltx_p">Advances in artificial intelligence technology have endowed computational pathology
                    with new capabilities, while the application-level focus on decision-making processes also places
                    higher demands on the capabilities of computational pathology models. Moreover, current research
                    lacks validation and investigation into how AI models collaborate with experts and pathologists, and
                    the modalities of integrated information of these models remain confined to text and images.
                    Therefore, designing an efficient AI assistant for pathology research and diagnosis holds
                    significant practical importance.</p><button class="sr-only button" style="display: none;">Report
                    issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S3.p2">
                <p class="ltx_p">Here we present TeamPath, an advanced AI copilot to advance research in computational
                    pathology and disease diagnosis by formulating a multi-task AI assistant, which supports various
                    tasks with an automatic router for solution selection. To empower the generalization ability and
                    thinking process of VLM, we utilize reinforcement learning to finetune a reasoning-enhanced VLM,
                    which serves for handling the pathology visual question-answer task. We perform comprehensive
                    analyses to select the best training strategy for this task. We also design a
                    self-verification/correction pipeline to fix the imperfect answer and reasoning paths proposed by
                    experts for the Pathology VQA task. Furthermore, to successfully summarize the caption of a given
                    image, we further train a summarization-enhanced VLM for caption generation and image understanding.
                    To demonstrate the capacity of VLM for multimodal information generation, we also finetune a model
                    for generating spatial transcriptomic data directly from ROIs, which also provides a direction for
                    exploring the multimodal information integration for utilizing the potentials of histopathology
                    images.</p><button class="sr-only button" style="display: none;">Report issue for preceding
                    element</button>
            </div>
            <div class="ltx_para" id="S3.p3">
                <p class="ltx_p">Our experimental results show that TeamPath works as a state-of-the-art method in
                    several tasks by comparing it with advanced VLMs from general domains, medical domains, and
                    pathology domains. TeamPath can also produce more reliable reasoning paths for disease diagnosis and
                    feature analysis. TeamPath also successfully identifies the incorrect information existing in
                    pathologists’ answers and reasoning processes and provides the correction suggestions as well as
                    corrected answers within a reasonable response time. Finally, TeamPath works as a strong generator
                    for image caption and transcriptomic information, which supports its capacity in understanding
                    ROI-level information and integrating bimolecular information with a multi-task system.
                </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S3.p4">
                <p class="ltx_p">There are also limitations of the current implementation of TeamPath. First, the
                    improvement of base VLMs will affect the choices of components in this system, and thus, we expect
                    to see regular model updates. Second, our task selection process relies on a trained LLM as a
                    router, which might be substituted with a mixture-of-expert setting. We also found that in rare
                    cases, the model’s reasoning process and its conclusion may not align (Extended Data Figure <a
                        class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#A4.F9"
                        title="Extended Data Fig. 9 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">9</span></a>), but it could be identified by physicians.
                    Finally, we have not considered the privacy issues involved in pathological image analysis. Although
                    we have made every effort to ensure that personal privacy information is not used for training,
                    exploring defenses against attacks in this area is also important. In the future, we will work on
                    these directions to make the system alive and improve its capacity and robustness.</p><button
                    class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
        </section>
        <section class="ltx_section" id="S4" lang="en">
            <h2 class="ltx_title ltx_title_section">
                <span class="ltx_tag ltx_tag_section">4 </span>Methods
            </h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S4.p1">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">Problem definition.</span> In this manuscript, we
                    aim to construct a pathology-expert-level visual language model <math alttext="\mathcal{M}()"
                        class="ltx_Math" display="inline" id="S4.p1.m1" intent=":literal">
                        <semantics>
                            <mrow>
                                <mi class="ltx_font_mathcaligraphic">ℳ</mi>
                                <mo lspace="0em" rspace="0em">​</mo>
                                <mrow>
                                    <mo stretchy="false">(</mo>
                                    <mo stretchy="false">)</mo>
                                </mrow>
                            </mrow>
                            <annotation encoding="application/x-tex">\mathcal{M}()</annotation>
                        </semantics>
                    </math> which accepts text prompts <math alttext="T" class="ltx_Math" display="inline" id="S4.p1.m2"
                        intent=":literal">
                        <semantics>
                            <mi>T</mi>
                            <annotation encoding="application/x-tex">T</annotation>
                        </semantics>
                    </math> and pathology image <math alttext="P" class="ltx_Math" display="inline" id="S4.p1.m3"
                        intent=":literal">
                        <semantics>
                            <mi>P</mi>
                            <annotation encoding="application/x-tex">P</annotation>
                        </semantics>
                    </math> as inputs. The outputs of our model follow the instructions and information provided in
                    <math alttext="T" class="ltx_Math" display="inline" id="S4.p1.m4" intent=":literal">
                        <semantics>
                            <mi>T</mi>
                            <annotation encoding="application/x-tex">T</annotation>
                        </semantics>
                    </math> and <math alttext="P" class="ltx_Math" display="inline" id="S4.p1.m5" intent=":literal">
                        <semantics>
                            <mi>P</mi>
                            <annotation encoding="application/x-tex">P</annotation>
                        </semantics>
                    </math>. To train <math alttext="\mathcal{M}()" class="ltx_Math" display="inline" id="S4.p1.m6"
                        intent=":literal">
                        <semantics>
                            <mrow>
                                <mi class="ltx_font_mathcaligraphic">ℳ</mi>
                                <mo lspace="0em" rspace="0em">​</mo>
                                <mrow>
                                    <mo stretchy="false">(</mo>
                                    <mo stretchy="false">)</mo>
                                </mrow>
                            </mrow>
                            <annotation encoding="application/x-tex">\mathcal{M}()</annotation>
                        </semantics>
                    </math>, we collect a dataset <math alttext="D_{p}=\{(T_{1},P_{1}),...,(T_{n},P_{n})\}_{1}^{n}"
                        class="ltx_Math" display="inline" id="S4.p1.m7" intent=":literal">
                        <semantics>
                            <mrow>
                                <msub>
                                    <mi>D</mi>
                                    <mi>p</mi>
                                </msub>
                                <mo>=</mo>
                                <msubsup>
                                    <mrow>
                                        <mo stretchy="false">{</mo>
                                        <mrow>
                                            <mo stretchy="false">(</mo>
                                            <msub>
                                                <mi>T</mi>
                                                <mn>1</mn>
                                            </msub>
                                            <mo>,</mo>
                                            <msub>
                                                <mi>P</mi>
                                                <mn>1</mn>
                                            </msub>
                                            <mo stretchy="false">)</mo>
                                        </mrow>
                                        <mo>,</mo>
                                        <mi mathvariant="normal">…</mi>
                                        <mo>,</mo>
                                        <mrow>
                                            <mo stretchy="false">(</mo>
                                            <msub>
                                                <mi>T</mi>
                                                <mi>n</mi>
                                            </msub>
                                            <mo>,</mo>
                                            <msub>
                                                <mi>P</mi>
                                                <mi>n</mi>
                                            </msub>
                                            <mo stretchy="false">)</mo>
                                        </mrow>
                                        <mo stretchy="false">}</mo>
                                    </mrow>
                                    <mn>1</mn>
                                    <mi>n</mi>
                                </msubsup>
                            </mrow>
                            <annotation encoding="application/x-tex">D_{p}=\{(T_{1},P_{1}),...,(T_{n},P_{n})\}_{1}^{n}
                            </annotation>
                        </semantics>
                    </math> with <math alttext="n" class="ltx_Math" display="inline" id="S4.p1.m8" intent=":literal">
                        <semantics>
                            <mi>n</mi>
                            <annotation encoding="application/x-tex">n</annotation>
                        </semantics>
                    </math> items for training, and transfer the trained model to various downstream applications.</p>
                <button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p2">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">Constructing TeamPath as a system.</span> To
                    enhance our system’s multitasking capabilities, we adopted a method commonly used in current basic
                    model development, namely training a language model-based router (<math alttext="\mathcal{R}()"
                        class="ltx_Math" display="inline" id="S4.p2.m1" intent=":literal">
                        <semantics>
                            <mrow>
                                <mi class="ltx_font_mathcaligraphic">ℛ</mi>
                                <mo lspace="0em" rspace="0em">​</mo>
                                <mrow>
                                    <mo stretchy="false">(</mo>
                                    <mo stretchy="false">)</mo>
                                </mrow>
                            </mrow>
                            <annotation encoding="application/x-tex">\mathcal{R}()</annotation>
                        </semantics>
                    </math>) according to tasks and requirements. This router accepts questions as input data and
                    outputs the model it selects to solve specific problems. The advantage of this design is to unify
                    the TeamPath as a system for various downstream applications in digital pathology, and select the
                    solution that best meets needs to save costs and improve model capabilities. We mark the best
                    solution settings (one of the following choices: Reinforcement Learning (RL) <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">sheng2024hybridflow</span>)</cite>,
                    Supervised FineTuning (SFT) <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">zheng-etal-2024-llamafactory</span>)</cite>,
                    and Test-Time Scaling (TTS) <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">snell2024scaling</span>)</cite>) of each
                    question, and train <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S4.p2.m2"
                        intent=":literal">
                        <semantics>
                            <mi class="ltx_font_mathcaligraphic">ℛ</mi>
                            <annotation encoding="application/x-tex">\mathcal{R}</annotation>
                        </semantics>
                    </math> with questions and choices. Here, RL is used for solving questions that require reasoning,
                    and SFT is used for summarization and cross-modality generation. Since AI Copilot needs interactions
                    with physicians, TTC is used for tasks requiring human-AI collaboration. Current base model of
                    TeamPath is Patho-R1-7B <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2025patho</span>)</cite>, which is
                    selected after carefully comparing it with different LMMs such as Qwen2.5VL-7B <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">team2024qwen2</span>)</cite>, Qwen2.5VL-3B
                    <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">team2024qwen2</span>)</cite>,
                    MedVLThinker-7B <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">huang2025medvlthinker</span>)</cite>,
                    PathGen-LLaVA-13B <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">sunpathgen</span>)</cite>, InternVL3-8B
                    <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2025internvl3</span>)</cite>, and
                    MedGemma-4B <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">sellergren2025medgemma</span>)</cite>.</p>
                <button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p3">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">Empowering TeamPath with reasoning
                        capacities.</span> To enhance the reasoning capabilities of TeamPath for complex pathological
                    analysis, we adopt Group Relative Policy Optimization (GRPO), an efficient reinforcement learning
                    algorithm that forgoes the critic model used in traditional PPO <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">shao2024deepseekmath</span>)</cite>.</p>
                <button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p4">
                <p class="ltx_p">For each pathological query <math alttext="q" class="ltx_Math" display="inline"
                        id="S4.p4.m1" intent=":literal">
                        <semantics>
                            <mi>q</mi>
                            <annotation encoding="application/x-tex">q</annotation>
                        </semantics>
                    </math>, GRPO samples a group of <math alttext="G" class="ltx_Math" display="inline" id="S4.p4.m2"
                        intent=":literal">
                        <semantics>
                            <mi>G</mi>
                            <annotation encoding="application/x-tex">G</annotation>
                        </semantics>
                    </math> outputs <math alttext="\{o_{1},o_{2},\ldots,o_{G}\}" class="ltx_Math" display="inline"
                        id="S4.p4.m3" intent=":literal">
                        <semantics>
                            <mrow>
                                <mo stretchy="false">{</mo>
                                <msub>
                                    <mi>o</mi>
                                    <mn>1</mn>
                                </msub>
                                <mo>,</mo>
                                <msub>
                                    <mi>o</mi>
                                    <mn>2</mn>
                                </msub>
                                <mo>,</mo>
                                <mi mathvariant="normal">…</mi>
                                <mo>,</mo>
                                <msub>
                                    <mi>o</mi>
                                    <mi>G</mi>
                                </msub>
                                <mo stretchy="false">}</mo>
                            </mrow>
                            <annotation encoding="application/x-tex">\{o_{1},o_{2},\ldots,o_{G}\}</annotation>
                        </semantics>
                    </math> from the current policy <math alttext="\pi_{\theta}" class="ltx_Math" display="inline"
                        id="S4.p4.m4" intent=":literal">
                        <semantics>
                            <msub>
                                <mi>π</mi>
                                <mi>θ</mi>
                            </msub>
                            <annotation encoding="application/x-tex">\pi_{\theta}</annotation>
                        </semantics>
                    </math> and optimizes the following objective:</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p5">
                <table class="ltx_equation ltx_eqn_table" id="S4.E1">
                    <tbody>
                        <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
                            <td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
                            <td class="ltx_eqn_cell ltx_align_center"><math
                                    alttext="J_{GRPO}(\theta)=\mathbb{E}\left[q\sim P(Q),\{o_{i}\}_{i=1}^{G}\sim\pi_{\theta_{old}}(O|q)\right]\left[\frac{1}{G}\sum_{i=1}^{G}\frac{1}{|o_{i}|}\sum_{t=1}^{|o_{i}|}\hat{A}_{i,t}\frac{\pi_{\theta}(o_{i,t}|q,o_{i,&lt;t})}{\pi_{\theta_{old}}(o_{i,t}|q,o_{i,&lt;t})}-\beta D_{KL}(\pi_{\theta}||\pi_{ref})\right],"
                                    class="ltx_math_unparsed" display="block" id="S4.E1.m1" intent=":literal">
                                    <semantics>
                                        <mrow>
                                            <msub>
                                                <mi>J</mi>
                                                <mrow>
                                                    <mi>G</mi>
                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                    <mi>R</mi>
                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                    <mi>P</mi>
                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                    <mi>O</mi>
                                                </mrow>
                                            </msub>
                                            <mrow>
                                                <mo stretchy="false">(</mo>
                                                <mi>θ</mi>
                                                <mo stretchy="false">)</mo>
                                            </mrow>
                                            <mo>=</mo>
                                            <mi>𝔼</mi>
                                            <mrow>
                                                <mo>[</mo>
                                                <mi>q</mi>
                                                <mo>∼</mo>
                                                <mi>P</mi>
                                                <mrow>
                                                    <mo stretchy="false">(</mo>
                                                    <mi>Q</mi>
                                                    <mo stretchy="false">)</mo>
                                                </mrow>
                                                <mo>,</mo>
                                                <msubsup>
                                                    <mrow>
                                                        <mo stretchy="false">{</mo>
                                                        <msub>
                                                            <mi>o</mi>
                                                            <mi>i</mi>
                                                        </msub>
                                                        <mo stretchy="false">}</mo>
                                                    </mrow>
                                                    <mrow>
                                                        <mi>i</mi>
                                                        <mo>=</mo>
                                                        <mn>1</mn>
                                                    </mrow>
                                                    <mi>G</mi>
                                                </msubsup>
                                                <mo>∼</mo>
                                                <msub>
                                                    <mi>π</mi>
                                                    <msub>
                                                        <mi>θ</mi>
                                                        <mrow>
                                                            <mi>o</mi>
                                                            <mo lspace="0em" rspace="0em">​</mo>
                                                            <mi>l</mi>
                                                            <mo lspace="0em" rspace="0em">​</mo>
                                                            <mi>d</mi>
                                                        </mrow>
                                                    </msub>
                                                </msub>
                                                <mrow>
                                                    <mo stretchy="false">(</mo>
                                                    <mi>O</mi>
                                                    <mo fence="false" rspace="0.167em" stretchy="false">|</mo>
                                                    <mi>q</mi>
                                                    <mo stretchy="false">)</mo>
                                                </mrow>
                                                <mo>]</mo>
                                            </mrow>
                                            <mrow>
                                                <mo>[</mo>
                                                <mfrac>
                                                    <mn>1</mn>
                                                    <mi>G</mi>
                                                </mfrac>
                                                <munderover>
                                                    <mo movablelimits="false">∑</mo>
                                                    <mrow>
                                                        <mi>i</mi>
                                                        <mo>=</mo>
                                                        <mn>1</mn>
                                                    </mrow>
                                                    <mi>G</mi>
                                                </munderover>
                                                <mfrac>
                                                    <mn>1</mn>
                                                    <mrow>
                                                        <mo stretchy="false">|</mo>
                                                        <msub>
                                                            <mi>o</mi>
                                                            <mi>i</mi>
                                                        </msub>
                                                        <mo stretchy="false">|</mo>
                                                    </mrow>
                                                </mfrac>
                                                <munderover>
                                                    <mo movablelimits="false">∑</mo>
                                                    <mrow>
                                                        <mi>t</mi>
                                                        <mo>=</mo>
                                                        <mn>1</mn>
                                                    </mrow>
                                                    <mrow>
                                                        <mo stretchy="false">|</mo>
                                                        <msub>
                                                            <mi>o</mi>
                                                            <mi>i</mi>
                                                        </msub>
                                                        <mo stretchy="false">|</mo>
                                                    </mrow>
                                                </munderover>
                                                <msub>
                                                    <mover accent="true">
                                                        <mi>A</mi>
                                                        <mo>^</mo>
                                                    </mover>
                                                    <mrow>
                                                        <mi>i</mi>
                                                        <mo>,</mo>
                                                        <mi>t</mi>
                                                    </mrow>
                                                </msub>
                                                <mfrac>
                                                    <mrow>
                                                        <msub>
                                                            <mi>π</mi>
                                                            <mi>θ</mi>
                                                        </msub>
                                                        <mo lspace="0em" rspace="0em">​</mo>
                                                        <mrow>
                                                            <mo stretchy="false">(</mo>
                                                            <mrow>
                                                                <msub>
                                                                    <mi>o</mi>
                                                                    <mrow>
                                                                        <mi>i</mi>
                                                                        <mo>,</mo>
                                                                        <mi>t</mi>
                                                                    </mrow>
                                                                </msub>
                                                                <mo fence="false">|</mo>
                                                                <mrow>
                                                                    <mi>q</mi>
                                                                    <mo>,</mo>
                                                                    <msub>
                                                                        <mi>o</mi>
                                                                        <mrow>
                                                                            <mi>i</mi>
                                                                            <mo>,</mo>
                                                                            <mrow>
                                                                                <mi></mi>
                                                                                <mo>&lt;</mo>
                                                                                <mi>t</mi>
                                                                            </mrow>
                                                                        </mrow>
                                                                    </msub>
                                                                </mrow>
                                                            </mrow>
                                                            <mo stretchy="false">)</mo>
                                                        </mrow>
                                                    </mrow>
                                                    <mrow>
                                                        <msub>
                                                            <mi>π</mi>
                                                            <msub>
                                                                <mi>θ</mi>
                                                                <mrow>
                                                                    <mi>o</mi>
                                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                                    <mi>l</mi>
                                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                                    <mi>d</mi>
                                                                </mrow>
                                                            </msub>
                                                        </msub>
                                                        <mo lspace="0em" rspace="0em">​</mo>
                                                        <mrow>
                                                            <mo stretchy="false">(</mo>
                                                            <mrow>
                                                                <msub>
                                                                    <mi>o</mi>
                                                                    <mrow>
                                                                        <mi>i</mi>
                                                                        <mo>,</mo>
                                                                        <mi>t</mi>
                                                                    </mrow>
                                                                </msub>
                                                                <mo fence="false">|</mo>
                                                                <mrow>
                                                                    <mi>q</mi>
                                                                    <mo>,</mo>
                                                                    <msub>
                                                                        <mi>o</mi>
                                                                        <mrow>
                                                                            <mi>i</mi>
                                                                            <mo>,</mo>
                                                                            <mrow>
                                                                                <mi></mi>
                                                                                <mo>&lt;</mo>
                                                                                <mi>t</mi>
                                                                            </mrow>
                                                                        </mrow>
                                                                    </msub>
                                                                </mrow>
                                                            </mrow>
                                                            <mo stretchy="false">)</mo>
                                                        </mrow>
                                                    </mrow>
                                                </mfrac>
                                                <mo>−</mo>
                                                <mi>β</mi>
                                                <msub>
                                                    <mi>D</mi>
                                                    <mrow>
                                                        <mi>K</mi>
                                                        <mo lspace="0em" rspace="0em">​</mo>
                                                        <mi>L</mi>
                                                    </mrow>
                                                </msub>
                                                <mrow>
                                                    <mo stretchy="false">(</mo>
                                                    <msub>
                                                        <mi>π</mi>
                                                        <mi>θ</mi>
                                                    </msub>
                                                    <mo fence="false" rspace="0.167em" stretchy="false">|</mo>
                                                    <mo fence="false" rspace="0.167em" stretchy="false">|</mo>
                                                    <msub>
                                                        <mi>π</mi>
                                                        <mrow>
                                                            <mi>r</mi>
                                                            <mo lspace="0em" rspace="0em">​</mo>
                                                            <mi>e</mi>
                                                            <mo lspace="0em" rspace="0em">​</mo>
                                                            <mi>f</mi>
                                                        </mrow>
                                                    </msub>
                                                    <mo stretchy="false">)</mo>
                                                </mrow>
                                                <mo>]</mo>
                                            </mrow>
                                            <mo>,</mo>
                                        </mrow>
                                        <annotation encoding="application/x-tex">J_{GRPO}(\theta)=\mathbb{E}\left[q\sim
                                            P(Q),\{o_{i}\}_{i=1}^{G}\sim\pi_{\theta_{old}}(O|q)\right]\left[\frac{1}{G}\sum_{i=1}^{G}\frac{1}{|o_{i}|}\sum_{t=1}^{|o_{i}|}\hat{A}_{i,t}\frac{\pi_{\theta}(o_{i,t}|q,o_{i,&lt;t})}{\pi_{\theta_{old}}(o_{i,t}|q,o_{i,&lt;t})}-\beta
                                            D_{KL}(\pi_{\theta}||\pi_{ref})\right],</annotation>
                                    </semantics>
                                </math></td>
                            <td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
                            <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span
                                    class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="ltx_para" id="S4.p6">
                <p class="ltx_p">where the key novelty lies in the group-relative advantage estimation:</p><button
                    class="sr-only button" style="display: none;">Report issue for preceding element</button>
                <table class="ltx_equation ltx_eqn_table" id="S4.E2">
                    <tbody>
                        <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
                            <td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
                            <td class="ltx_eqn_cell ltx_align_center"><math
                                    alttext="\hat{A}_{i,t}=\frac{r_{i}-\text{mean}(\mathbf{r})}{\text{std}(\mathbf{r})}."
                                    class="ltx_Math" display="block" id="S4.E2.m1" intent=":literal">
                                    <semantics>
                                        <mrow>
                                            <mrow>
                                                <msub>
                                                    <mover accent="true">
                                                        <mi>A</mi>
                                                        <mo>^</mo>
                                                    </mover>
                                                    <mrow>
                                                        <mi>i</mi>
                                                        <mo>,</mo>
                                                        <mi>t</mi>
                                                    </mrow>
                                                </msub>
                                                <mo>=</mo>
                                                <mfrac>
                                                    <mrow>
                                                        <msub>
                                                            <mi>r</mi>
                                                            <mi>i</mi>
                                                        </msub>
                                                        <mo>−</mo>
                                                        <mrow>
                                                            <mtext>mean</mtext>
                                                            <mo lspace="0em" rspace="0em">​</mo>
                                                            <mrow>
                                                                <mo stretchy="false">(</mo>
                                                                <mi>𝐫</mi>
                                                                <mo stretchy="false">)</mo>
                                                            </mrow>
                                                        </mrow>
                                                    </mrow>
                                                    <mrow>
                                                        <mtext>std</mtext>
                                                        <mo lspace="0em" rspace="0em">​</mo>
                                                        <mrow>
                                                            <mo stretchy="false">(</mo>
                                                            <mi>𝐫</mi>
                                                            <mo stretchy="false">)</mo>
                                                        </mrow>
                                                    </mrow>
                                                </mfrac>
                                            </mrow>
                                            <mo lspace="0em">.</mo>
                                        </mrow>
                                        <annotation encoding="application/x-tex">
                                            \hat{A}_{i,t}=\frac{r_{i}-\text{mean}(\mathbf{r})}{\text{std}(\mathbf{r})}.
                                        </annotation>
                                    </semantics>
                                </math></td>
                            <td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
                            <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span
                                    class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="ltx_para" id="S4.p7">
                <p class="ltx_p">Here, <math alttext="\mathbf{r}=\{r_{1},r_{2},\ldots,r_{G}\}" class="ltx_Math"
                        display="inline" id="S4.p7.m1" intent=":literal">
                        <semantics>
                            <mrow>
                                <mi>𝐫</mi>
                                <mo>=</mo>
                                <mrow>
                                    <mo stretchy="false">{</mo>
                                    <msub>
                                        <mi>r</mi>
                                        <mn>1</mn>
                                    </msub>
                                    <mo>,</mo>
                                    <msub>
                                        <mi>r</mi>
                                        <mn>2</mn>
                                    </msub>
                                    <mo>,</mo>
                                    <mi mathvariant="normal">…</mi>
                                    <mo>,</mo>
                                    <msub>
                                        <mi>r</mi>
                                        <mi>G</mi>
                                    </msub>
                                    <mo stretchy="false">}</mo>
                                </mrow>
                            </mrow>
                            <annotation encoding="application/x-tex">\mathbf{r}=\{r_{1},r_{2},\ldots,r_{G}\}
                            </annotation>
                        </semantics>
                    </math> represents the reward scores for all outputs in the group, obtained from a reward model
                    trained on the quality of pathological reasoning. This group-relative formulation eliminates the
                    need for a separate value function <math alttext="V_{\psi}" class="ltx_Math" display="inline"
                        id="S4.p7.m2" intent=":literal">
                        <semantics>
                            <msub>
                                <mi>V</mi>
                                <mi>ψ</mi>
                            </msub>
                            <annotation encoding="application/x-tex">V_{\psi}</annotation>
                        </semantics>
                    </math> required in PPO, significantly reducing computational overhead while maintaining training
                    stability.</p><button class="sr-only button" style="display: none;">Report issue for preceding
                    element</button>
            </div>
            <div class="ltx_para" id="S4.p8">
                <p class="ltx_p">For GRPO, the reward of question <math alttext="i" class="ltx_Math" display="inline"
                        id="S4.p8.m1" intent=":literal">
                        <semantics>
                            <mi>i</mi>
                            <annotation encoding="application/x-tex">i</annotation>
                        </semantics>
                    </math> is:</p><button class="sr-only button" style="display: none;">Report issue for preceding
                    element</button>
            </div>
            <div class="ltx_para" id="S4.p9">
                <table class="ltx_equation ltx_eqn_table" id="S4.E3">
                    <tbody>
                        <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
                            <td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
                            <td class="ltx_eqn_cell ltx_align_center"><math alttext="r_{i}=r(\hat{y}_{i},y_{i})=\begin{cases}1,&amp;\text{ is\_equivalent }(\hat{y}_{i},y_{i})\\
0,&amp;\text{ otherwise }\end{cases}," class="ltx_Math" display="block" id="S4.E3.m1" intent=":literal">
                                    <semantics>
                                        <mrow>
                                            <mrow>
                                                <msub>
                                                    <mi>r</mi>
                                                    <mi>i</mi>
                                                </msub>
                                                <mo>=</mo>
                                                <mrow>
                                                    <mi>r</mi>
                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                    <mrow>
                                                        <mo stretchy="false">(</mo>
                                                        <msub>
                                                            <mover accent="true">
                                                                <mi>y</mi>
                                                                <mo>^</mo>
                                                            </mover>
                                                            <mi>i</mi>
                                                        </msub>
                                                        <mo>,</mo>
                                                        <msub>
                                                            <mi>y</mi>
                                                            <mi>i</mi>
                                                        </msub>
                                                        <mo stretchy="false">)</mo>
                                                    </mrow>
                                                </mrow>
                                                <mo>=</mo>
                                                <mrow>
                                                    <mo>{</mo>
                                                    <mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt">
                                                        <mtr>
                                                            <mtd class="ltx_align_left" columnalign="left">
                                                                <mrow>
                                                                    <mn>1</mn>
                                                                    <mo>,</mo>
                                                                </mrow>
                                                            </mtd>
                                                            <mtd class="ltx_align_left" columnalign="left">
                                                                <mrow>
                                                                    <mtext>&nbsp;is_equivalent&nbsp;</mtext>
                                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                                    <mrow>
                                                                        <mo stretchy="false">(</mo>
                                                                        <msub>
                                                                            <mover accent="true">
                                                                                <mi>y</mi>
                                                                                <mo>^</mo>
                                                                            </mover>
                                                                            <mi>i</mi>
                                                                        </msub>
                                                                        <mo>,</mo>
                                                                        <msub>
                                                                            <mi>y</mi>
                                                                            <mi>i</mi>
                                                                        </msub>
                                                                        <mo stretchy="false">)</mo>
                                                                    </mrow>
                                                                </mrow>
                                                            </mtd>
                                                        </mtr>
                                                        <mtr>
                                                            <mtd class="ltx_align_left" columnalign="left">
                                                                <mrow>
                                                                    <mn>0</mn>
                                                                    <mo>,</mo>
                                                                </mrow>
                                                            </mtd>
                                                            <mtd class="ltx_align_left" columnalign="left">
                                                                <mtext>&nbsp;otherwise&nbsp;</mtext>
                                                            </mtd>
                                                        </mtr>
                                                    </mtable>
                                                </mrow>
                                            </mrow>
                                            <mo>,</mo>
                                        </mrow>
                                        <annotation encoding="application/x-tex">
                                            r_{i}=r(\hat{y}_{i},y_{i})=\begin{cases}1,&amp;\text{ is\_equivalent
                                            }(\hat{y}_{i},y_{i})\\
                                            0,&amp;\text{ otherwise }\end{cases},</annotation>
                                    </semantics>
                                </math></td>
                            <td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
                            <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span
                                    class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
                        </tr>
                    </tbody>
                </table>
                <p class="ltx_p">where <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S4.p9.m1"
                        intent=":literal">
                        <semantics>
                            <mover accent="true">
                                <mi>y</mi>
                                <mo>^</mo>
                            </mover>
                            <annotation encoding="application/x-tex">\hat{y}</annotation>
                        </semantics>
                    </math> and <math alttext="y" class="ltx_Math" display="inline" id="S4.p9.m2" intent=":literal">
                        <semantics>
                            <mi>y</mi>
                            <annotation encoding="application/x-tex">y</annotation>
                        </semantics>
                    </math> represent the model outputs and observed answers, respectively. is_equivalent() is a
                    function used to determine if the answer is correct or not.</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p10">
                <p class="ltx_p">In our ablation studies, we also consider introducing open-ended questions to model
                    training; in that case, we utilize the BLEU score as a reward. The reward for closed-ended samples
                    is the same, but for open-ended sample j, the reward is:</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p11">
                <table class="ltx_equation ltx_eqn_table" id="S4.E4">
                    <tbody>
                        <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
                            <td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
                            <td class="ltx_eqn_cell ltx_align_center"><math
                                    alttext="r_{j}=r(\hat{y}_{j},y_{j})=\text{BLEU}(\hat{y}_{j},y_{j})."
                                    class="ltx_Math" display="block" id="S4.E4.m1" intent=":literal">
                                    <semantics>
                                        <mrow>
                                            <mrow>
                                                <msub>
                                                    <mi>r</mi>
                                                    <mi>j</mi>
                                                </msub>
                                                <mo>=</mo>
                                                <mrow>
                                                    <mi>r</mi>
                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                    <mrow>
                                                        <mo stretchy="false">(</mo>
                                                        <msub>
                                                            <mover accent="true">
                                                                <mi>y</mi>
                                                                <mo>^</mo>
                                                            </mover>
                                                            <mi>j</mi>
                                                        </msub>
                                                        <mo>,</mo>
                                                        <msub>
                                                            <mi>y</mi>
                                                            <mi>j</mi>
                                                        </msub>
                                                        <mo stretchy="false">)</mo>
                                                    </mrow>
                                                </mrow>
                                                <mo>=</mo>
                                                <mrow>
                                                    <mtext>BLEU</mtext>
                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                    <mrow>
                                                        <mo stretchy="false">(</mo>
                                                        <msub>
                                                            <mover accent="true">
                                                                <mi>y</mi>
                                                                <mo>^</mo>
                                                            </mover>
                                                            <mi>j</mi>
                                                        </msub>
                                                        <mo>,</mo>
                                                        <msub>
                                                            <mi>y</mi>
                                                            <mi>j</mi>
                                                        </msub>
                                                        <mo stretchy="false">)</mo>
                                                    </mrow>
                                                </mrow>
                                            </mrow>
                                            <mo lspace="0em">.</mo>
                                        </mrow>
                                        <annotation encoding="application/x-tex">
                                            r_{j}=r(\hat{y}_{j},y_{j})=\text{BLEU}(\hat{y}_{j},y_{j}).</annotation>
                                    </semantics>
                                </math></td>
                            <td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
                            <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span
                                    class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="ltx_para" id="S4.p12">
                <p class="ltx_p">The comparative nature of this approach aligns naturally with pathological diagnosis
                    workflows, where medical experts simultaneously evaluate multiple diagnostic hypotheses. By learning
                    from the relative quality of responses within each group, TeamPath develops more nuanced reasoning
                    capabilities for tasks requiring differential diagnosis, evidence synthesis, and step-by-step
                    pathological analysis.</p><button class="sr-only button" style="display: none;">Report issue for
                    preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p13">
                <p class="ltx_p">In our ablation studies, we also consider Dynamic sAmpling Policy Optimization (DAPO)
                    as an alternative reinforcement learning algorithm. DAPO removes the KL divergence and adjusts the
                    group-level normalization method. That is:</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p14">
                <table class="ltx_equationgroup ltx_eqn_table" id="S4.E5">
                    <tbody>
                        <tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S4.E5X">
                            <td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
                            <td class="ltx_td ltx_align_right ltx_eqn_cell"><math
                                    alttext="\displaystyle\mathcal{J}_{\mathrm{DAPO}}(\theta)=" class="ltx_Math"
                                    display="inline" id="S4.E5X.m2" intent=":literal">
                                    <semantics>
                                        <mrow>
                                            <mrow>
                                                <msub>
                                                    <mi class="ltx_font_mathcaligraphic">𝒥</mi>
                                                    <mi>DAPO</mi>
                                                </msub>
                                                <mo lspace="0em" rspace="0em">​</mo>
                                                <mrow>
                                                    <mo stretchy="false">(</mo>
                                                    <mi>θ</mi>
                                                    <mo stretchy="false">)</mo>
                                                </mrow>
                                            </mrow>
                                            <mo>=</mo>
                                            <mi></mi>
                                        </mrow>
                                        <annotation encoding="application/x-tex">
                                            \displaystyle\mathcal{J}_{\mathrm{DAPO}}(\theta)=</annotation>
                                    </semantics>
                                </math></td>
                            <td class="ltx_td ltx_align_left ltx_eqn_cell"><math
                                    alttext="\displaystyle\mathbb{E}_{(q,y)\sim\mathcal{D},\left\{o_{i}\right\}_{i=1}^{G}\sim\pi_{\theta_{\text{old }}}(\cdot\mid q)}"
                                    class="ltx_math_unparsed" display="inline" id="S4.E5X.m3" intent=":literal">
                                    <semantics>
                                        <msub>
                                            <mi>𝔼</mi>
                                            <mrow>
                                                <mrow>
                                                    <mo stretchy="false">(</mo>
                                                    <mi>q</mi>
                                                    <mo>,</mo>
                                                    <mi>y</mi>
                                                    <mo stretchy="false">)</mo>
                                                </mrow>
                                                <mo>∼</mo>
                                                <mi class="ltx_font_mathcaligraphic">𝒟</mi>
                                                <mo>,</mo>
                                                <msubsup>
                                                    <mrow>
                                                        <mo>{</mo>
                                                        <msub>
                                                            <mi>o</mi>
                                                            <mi>i</mi>
                                                        </msub>
                                                        <mo>}</mo>
                                                    </mrow>
                                                    <mrow>
                                                        <mi>i</mi>
                                                        <mo>=</mo>
                                                        <mn>1</mn>
                                                    </mrow>
                                                    <mi>G</mi>
                                                </msubsup>
                                                <mo>∼</mo>
                                                <msub>
                                                    <mi>π</mi>
                                                    <msub>
                                                        <mi>θ</mi>
                                                        <mtext>old&nbsp;</mtext>
                                                    </msub>
                                                </msub>
                                                <mrow>
                                                    <mo stretchy="false">(</mo>
                                                    <mo lspace="0em" rspace="0em">⋅</mo>
                                                    <mo lspace="0em" rspace="0.167em">∣</mo>
                                                    <mi>q</mi>
                                                    <mo stretchy="false">)</mo>
                                                </mrow>
                                            </mrow>
                                        </msub>
                                        <annotation encoding="application/x-tex">
                                            \displaystyle\mathbb{E}_{(q,y)\sim\mathcal{D},\left\{o_{i}\right\}_{i=1}^{G}\sim\pi_{\theta_{\text{old
                                            }}}(\cdot\mid q)}</annotation>
                                    </semantics>
                                </math></td>
                            <td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
                            <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="3"><span
                                    class="ltx_tag ltx_tag_equationgroup ltx_align_right">(5)</span></td>
                        </tr>
                        <tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S4.E5Xa">
                            <td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
                            <td class="ltx_td ltx_eqn_cell"></td>
                            <td class="ltx_td ltx_align_left ltx_eqn_cell"><math
                                    alttext="\displaystyle{\left[\frac{1}{\sum_{i=1}^{G}\left|o_{i}\right|}\sum_{i=1}^{G}\sum_{t=1}^{\left|o_{i}\right|}\min\left(ra_{i,t}(\theta)\hat{A}_{i,t},\operatorname{clip}\left(ra_{i,t}(\theta),1-\varepsilon_{\text{low }},1+\varepsilon_{\text{high }}\right)\hat{A}_{i,t}\right)\right]}"
                                    class="ltx_Math" display="inline" id="S4.E5Xa.m2" intent=":literal">
                                    <semantics>
                                        <mrow>
                                            <mo>[</mo>
                                            <mrow>
                                                <mstyle displaystyle="true">
                                                    <mfrac>
                                                        <mn>1</mn>
                                                        <mrow>
                                                            <msubsup>
                                                                <mo>∑</mo>
                                                                <mrow>
                                                                    <mi>i</mi>
                                                                    <mo>=</mo>
                                                                    <mn>1</mn>
                                                                </mrow>
                                                                <mi>G</mi>
                                                            </msubsup>
                                                            <mrow>
                                                                <mo lspace="0em">|</mo>
                                                                <msub>
                                                                    <mi>o</mi>
                                                                    <mi>i</mi>
                                                                </msub>
                                                                <mo>|</mo>
                                                            </mrow>
                                                        </mrow>
                                                    </mfrac>
                                                </mstyle>
                                                <mo lspace="0em" rspace="0em">​</mo>
                                                <mrow>
                                                    <mstyle displaystyle="true">
                                                        <munderover>
                                                            <mo movablelimits="false">∑</mo>
                                                            <mrow>
                                                                <mi>i</mi>
                                                                <mo>=</mo>
                                                                <mn>1</mn>
                                                            </mrow>
                                                            <mi>G</mi>
                                                        </munderover>
                                                    </mstyle>
                                                    <mrow>
                                                        <mstyle displaystyle="true">
                                                            <munderover>
                                                                <mo movablelimits="false">∑</mo>
                                                                <mrow>
                                                                    <mi>t</mi>
                                                                    <mo>=</mo>
                                                                    <mn>1</mn>
                                                                </mrow>
                                                                <mrow>
                                                                    <mo>|</mo>
                                                                    <msub>
                                                                        <mi>o</mi>
                                                                        <mi>i</mi>
                                                                    </msub>
                                                                    <mo>|</mo>
                                                                </mrow>
                                                            </munderover>
                                                        </mstyle>
                                                        <mrow>
                                                            <mi>min</mi>
                                                            <mo>⁡</mo>
                                                            <mrow>
                                                                <mo>(</mo>
                                                                <mrow>
                                                                    <mi>r</mi>
                                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                                    <msub>
                                                                        <mi>a</mi>
                                                                        <mrow>
                                                                            <mi>i</mi>
                                                                            <mo>,</mo>
                                                                            <mi>t</mi>
                                                                        </mrow>
                                                                    </msub>
                                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                                    <mrow>
                                                                        <mo stretchy="false">(</mo>
                                                                        <mi>θ</mi>
                                                                        <mo stretchy="false">)</mo>
                                                                    </mrow>
                                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                                    <msub>
                                                                        <mover accent="true">
                                                                            <mi>A</mi>
                                                                            <mo>^</mo>
                                                                        </mover>
                                                                        <mrow>
                                                                            <mi>i</mi>
                                                                            <mo>,</mo>
                                                                            <mi>t</mi>
                                                                        </mrow>
                                                                    </msub>
                                                                </mrow>
                                                                <mo>,</mo>
                                                                <mrow>
                                                                    <mrow>
                                                                        <mi>clip</mi>
                                                                        <mo>⁡</mo>
                                                                        <mrow>
                                                                            <mo>(</mo>
                                                                            <mrow>
                                                                                <mi>r</mi>
                                                                                <mo lspace="0em" rspace="0em">​</mo>
                                                                                <msub>
                                                                                    <mi>a</mi>
                                                                                    <mrow>
                                                                                        <mi>i</mi>
                                                                                        <mo>,</mo>
                                                                                        <mi>t</mi>
                                                                                    </mrow>
                                                                                </msub>
                                                                                <mo lspace="0em" rspace="0em">​</mo>
                                                                                <mrow>
                                                                                    <mo stretchy="false">(</mo>
                                                                                    <mi>θ</mi>
                                                                                    <mo stretchy="false">)</mo>
                                                                                </mrow>
                                                                            </mrow>
                                                                            <mo>,</mo>
                                                                            <mrow>
                                                                                <mn>1</mn>
                                                                                <mo>−</mo>
                                                                                <msub>
                                                                                    <mi>ε</mi>
                                                                                    <mtext>low&nbsp;</mtext>
                                                                                </msub>
                                                                            </mrow>
                                                                            <mo>,</mo>
                                                                            <mrow>
                                                                                <mn>1</mn>
                                                                                <mo>+</mo>
                                                                                <msub>
                                                                                    <mi>ε</mi>
                                                                                    <mtext>high&nbsp;</mtext>
                                                                                </msub>
                                                                            </mrow>
                                                                            <mo>)</mo>
                                                                        </mrow>
                                                                    </mrow>
                                                                    <mo lspace="0em" rspace="0em">​</mo>
                                                                    <msub>
                                                                        <mover accent="true">
                                                                            <mi>A</mi>
                                                                            <mo>^</mo>
                                                                        </mover>
                                                                        <mrow>
                                                                            <mi>i</mi>
                                                                            <mo>,</mo>
                                                                            <mi>t</mi>
                                                                        </mrow>
                                                                    </msub>
                                                                </mrow>
                                                                <mo>)</mo>
                                                            </mrow>
                                                        </mrow>
                                                    </mrow>
                                                </mrow>
                                            </mrow>
                                            <mo>]</mo>
                                        </mrow>
                                        <annotation encoding="application/x-tex">
                                            \displaystyle{\left[\frac{1}{\sum_{i=1}^{G}\left|o_{i}\right|}\sum_{i=1}^{G}\sum_{t=1}^{\left|o_{i}\right|}\min\left(ra_{i,t}(\theta)\hat{A}_{i,t},\operatorname{clip}\left(ra_{i,t}(\theta),1-\varepsilon_{\text{low
                                            }},1+\varepsilon_{\text{high }}\right)\hat{A}_{i,t}\right)\right]}
                                        </annotation>
                                    </semantics>
                                </math></td>
                            <td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
                        </tr>
                        <tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S4.E5Xb">
                            <td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
                            <td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\text{ s.t. }0"
                                    class="ltx_Math" display="inline" id="S4.E5Xb.m2" intent=":literal">
                                    <semantics>
                                        <mrow>
                                            <mtext>s.t.&nbsp;</mtext>
                                            <mo lspace="0em" rspace="0em">​</mo>
                                            <mn>0</mn>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\displaystyle\text{ s.t. }0
                                        </annotation>
                                    </semantics>
                                </math></td>
                            <td class="ltx_td ltx_align_left ltx_eqn_cell"><math
                                    alttext="\displaystyle&lt;\mid\left\{o_{i}\mid\text{ is\_equivalent }\left(y,o_{i}\right)\right\}\mid&lt;G,"
                                    class="ltx_Math" display="inline" id="S4.E5Xb.m3" intent=":literal">
                                    <semantics>
                                        <mrow>
                                            <mrow>
                                                <mi></mi>
                                                <mo rspace="0.1389em">&lt;</mo>
                                                <mrow>
                                                    <mo fence="true" lspace="0.1389em" rspace="0em">∣</mo>
                                                    <mrow>
                                                        <mo>{</mo>
                                                        <msub>
                                                            <mi>o</mi>
                                                            <mi>i</mi>
                                                        </msub>
                                                        <mo fence="true" lspace="0em" rspace="0em">∣</mo>
                                                        <mrow>
                                                            <mtext>&nbsp;is_equivalent&nbsp;</mtext>
                                                            <mo lspace="0em" rspace="0em">​</mo>
                                                            <mrow>
                                                                <mo>(</mo>
                                                                <mi>y</mi>
                                                                <mo>,</mo>
                                                                <msub>
                                                                    <mi>o</mi>
                                                                    <mi>i</mi>
                                                                </msub>
                                                                <mo>)</mo>
                                                            </mrow>
                                                        </mrow>
                                                        <mo>}</mo>
                                                    </mrow>
                                                    <mo fence="true" lspace="0em" rspace="0.1389em">∣</mo>
                                                </mrow>
                                                <mo lspace="0.1389em">&lt;</mo>
                                                <mi>G</mi>
                                            </mrow>
                                            <mo>,</mo>
                                        </mrow>
                                        <annotation encoding="application/x-tex">
                                            \displaystyle&lt;\mid\left\{o_{i}\mid\text{ is\_equivalent
                                            }\left(y,o_{i}\right)\right\}\mid&lt;G,</annotation>
                                    </semantics>
                                </math></td>
                            <td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
                        </tr>
                    </tbody>
                </table>
                <p class="ltx_p">where</p><button class="sr-only button" style="display: none;">Report issue for
                    preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p15">
                <table class="ltx_equation ltx_eqn_table" id="S4.E6">
                    <tbody>
                        <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
                            <td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
                            <td class="ltx_eqn_cell ltx_align_center"><math
                                    alttext="ra_{i,t}(\theta)=\frac{\pi_{\theta}\left(o_{i,t}\mid q,o_{i,&lt;t}\right)}{\pi_{\theta_{\text{old }}}\left(o_{i,t}\mid q,o_{i,&lt;t}\right)},\quad\hat{A}_{i,t}=\frac{r_{i}-\operatorname{mean}\left(\left\{r_{i}\right\}_{i=1}^{G}\right)}{\operatorname{std}\left(\left\{r_{i}\right\}_{i=1}^{G}\right)}."
                                    class="ltx_Math" display="block" id="S4.E6.m1" intent=":literal">
                                    <semantics>
                                        <mrow>
                                            <mrow>
                                                <mrow>
                                                    <mrow>
                                                        <mi>r</mi>
                                                        <mo lspace="0em" rspace="0em">​</mo>
                                                        <msub>
                                                            <mi>a</mi>
                                                            <mrow>
                                                                <mi>i</mi>
                                                                <mo>,</mo>
                                                                <mi>t</mi>
                                                            </mrow>
                                                        </msub>
                                                        <mo lspace="0em" rspace="0em">​</mo>
                                                        <mrow>
                                                            <mo stretchy="false">(</mo>
                                                            <mi>θ</mi>
                                                            <mo stretchy="false">)</mo>
                                                        </mrow>
                                                    </mrow>
                                                    <mo>=</mo>
                                                    <mfrac>
                                                        <mrow>
                                                            <msub>
                                                                <mi>π</mi>
                                                                <mi>θ</mi>
                                                            </msub>
                                                            <mo lspace="0em" rspace="0em">​</mo>
                                                            <mrow>
                                                                <mo>(</mo>
                                                                <mrow>
                                                                    <msub>
                                                                        <mi>o</mi>
                                                                        <mrow>
                                                                            <mi>i</mi>
                                                                            <mo>,</mo>
                                                                            <mi>t</mi>
                                                                        </mrow>
                                                                    </msub>
                                                                    <mo>∣</mo>
                                                                    <mrow>
                                                                        <mi>q</mi>
                                                                        <mo>,</mo>
                                                                        <msub>
                                                                            <mi>o</mi>
                                                                            <mrow>
                                                                                <mi>i</mi>
                                                                                <mo>,</mo>
                                                                                <mrow>
                                                                                    <mi></mi>
                                                                                    <mo>&lt;</mo>
                                                                                    <mi>t</mi>
                                                                                </mrow>
                                                                            </mrow>
                                                                        </msub>
                                                                    </mrow>
                                                                </mrow>
                                                                <mo>)</mo>
                                                            </mrow>
                                                        </mrow>
                                                        <mrow>
                                                            <msub>
                                                                <mi>π</mi>
                                                                <msub>
                                                                    <mi>θ</mi>
                                                                    <mtext>old&nbsp;</mtext>
                                                                </msub>
                                                            </msub>
                                                            <mo lspace="0em" rspace="0em">​</mo>
                                                            <mrow>
                                                                <mo>(</mo>
                                                                <mrow>
                                                                    <msub>
                                                                        <mi>o</mi>
                                                                        <mrow>
                                                                            <mi>i</mi>
                                                                            <mo>,</mo>
                                                                            <mi>t</mi>
                                                                        </mrow>
                                                                    </msub>
                                                                    <mo>∣</mo>
                                                                    <mrow>
                                                                        <mi>q</mi>
                                                                        <mo>,</mo>
                                                                        <msub>
                                                                            <mi>o</mi>
                                                                            <mrow>
                                                                                <mi>i</mi>
                                                                                <mo>,</mo>
                                                                                <mrow>
                                                                                    <mi></mi>
                                                                                    <mo>&lt;</mo>
                                                                                    <mi>t</mi>
                                                                                </mrow>
                                                                            </mrow>
                                                                        </msub>
                                                                    </mrow>
                                                                </mrow>
                                                                <mo>)</mo>
                                                            </mrow>
                                                        </mrow>
                                                    </mfrac>
                                                </mrow>
                                                <mo rspace="1.167em">,</mo>
                                                <mrow>
                                                    <msub>
                                                        <mover accent="true">
                                                            <mi>A</mi>
                                                            <mo>^</mo>
                                                        </mover>
                                                        <mrow>
                                                            <mi>i</mi>
                                                            <mo>,</mo>
                                                            <mi>t</mi>
                                                        </mrow>
                                                    </msub>
                                                    <mo>=</mo>
                                                    <mfrac>
                                                        <mrow>
                                                            <msub>
                                                                <mi>r</mi>
                                                                <mi>i</mi>
                                                            </msub>
                                                            <mo>−</mo>
                                                            <mrow>
                                                                <mi>mean</mi>
                                                                <mo>⁡</mo>
                                                                <mrow>
                                                                    <mo>(</mo>
                                                                    <msubsup>
                                                                        <mrow>
                                                                            <mo>{</mo>
                                                                            <msub>
                                                                                <mi>r</mi>
                                                                                <mi>i</mi>
                                                                            </msub>
                                                                            <mo>}</mo>
                                                                        </mrow>
                                                                        <mrow>
                                                                            <mi>i</mi>
                                                                            <mo>=</mo>
                                                                            <mn>1</mn>
                                                                        </mrow>
                                                                        <mi>G</mi>
                                                                    </msubsup>
                                                                    <mo>)</mo>
                                                                </mrow>
                                                            </mrow>
                                                        </mrow>
                                                        <mrow>
                                                            <mi>std</mi>
                                                            <mo>⁡</mo>
                                                            <mrow>
                                                                <mo>(</mo>
                                                                <msubsup>
                                                                    <mrow>
                                                                        <mo>{</mo>
                                                                        <msub>
                                                                            <mi>r</mi>
                                                                            <mi>i</mi>
                                                                        </msub>
                                                                        <mo>}</mo>
                                                                    </mrow>
                                                                    <mrow>
                                                                        <mi>i</mi>
                                                                        <mo>=</mo>
                                                                        <mn>1</mn>
                                                                    </mrow>
                                                                    <mi>G</mi>
                                                                </msubsup>
                                                                <mo>)</mo>
                                                            </mrow>
                                                        </mrow>
                                                    </mfrac>
                                                </mrow>
                                            </mrow>
                                            <mo lspace="0em">.</mo>
                                        </mrow>
                                        <annotation encoding="application/x-tex">
                                            ra_{i,t}(\theta)=\frac{\pi_{\theta}\left(o_{i,t}\mid
                                            q,o_{i,&lt;t}\right)}{\pi_{\theta_{\text{old }}}\left(o_{i,t}\mid
                                            q,o_{i,&lt;t}\right)},\quad\hat{A}_{i,t}=\frac{r_{i}-\operatorname{mean}\left(\left\{r_{i}\right\}_{i=1}^{G}\right)}{\operatorname{std}\left(\left\{r_{i}\right\}_{i=1}^{G}\right)}.
                                        </annotation>
                                    </semantics>
                                </math></td>
                            <td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
                            <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span
                                    class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="ltx_para" id="S4.p16">
                <p class="ltx_p">Here <math alttext="\epsilon" class="ltx_Math" display="inline" id="S4.p16.m1"
                        intent=":literal">
                        <semantics>
                            <mi>ϵ</mi>
                            <annotation encoding="application/x-tex">\epsilon</annotation>
                        </semantics>
                    </math> is the cut-off value to avoid gradient exploding.</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p17">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">Ablation studies of training framework.</span> To
                    demonstrate the efficiency and optimization of our training framework for this system, we have
                    considered several training strategies, including 1. Supervised finetuning (SFT), which collects
                    paired data with images and queries as inputs and answers as outputs; 2. Reinforcement Learning
                    (RL), which utilizes the same input and output data, but we train TeamPath with GRPO <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">shao2024deepseekmath</span>)</cite> or
                    DAPO <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">yu2025dapo</span>)</cite> to tackle the
                    reasoning capacity of selected base models; 3. SFT<math alttext="+" class="ltx_Math"
                        display="inline" id="S4.p17.m1" intent=":literal">
                        <semantics>
                            <mo>+</mo>
                            <annotation encoding="application/x-tex">+</annotation>
                        </semantics>
                    </math>RL, which utilizes the paired data with images, queries, and reasoning paths as inputs and
                    answers as outputs, to train TeamPath with SFT and then with RL. The first step of SFT training
                    ensures the model acquires knowledge in relevant pathological domains, while the second step of RL
                    training enhances the model’s generalization capabilities. Our base models used for ablation studies
                    include Qwen2.5VL-7B and Patho-R1-7B.</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p18">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">Using TeamPath as an AI Copilot to help
                        pathologists.</span> To formalize our method as an AI Assistant, we consider two case studies
                    inspired by the Path VQA experiments with pathologists. We invite the pathologists to answer 50
                    questions extracted from PathMMU from the five categories, and record their answers as well as
                    reasoning steps. Our first case is a verifier-corrector pipeline, which can detect the incorrect
                    answers made by pathologists and generate the correct answers. Our pipeline utilizes one verifier (a
                    VLM, default as o4-mini) to verify whether the answers and questions proposed by pathologists are
                    correct or not. If it is justified as wrong, we will call the corrector (also a VLM, default as
                    TeamPath used for Pathology VQA) to fix it. Otherwise, the correct answer will be returned. We have
                    a specific threshold to limit the number of epochs in this loop. Our algorithm is summarized in
                    Algorithm 1. We define the success of a self-verification/correction system as follows: if the
                    expert answer is correct, or the expert answer is wrong but the answer produced by this system is
                    correct.</p><button class="sr-only button" style="display: none;">Report issue for preceding
                    element</button>
            </div>
            <div class="ltx_para" id="S4.p19">
                <p class="ltx_p">The second case is a reasoning-correction pipeline. Here we have a reasoning corrector,
                    which takes the wrong answers and reasoning paths from pathologists, and generates the correct
                    reasoning path with the correct answer. This pipeline can detect the wrong information provided in
                    the reasoning process and generate the correct thinking steps. These two components focus on
                    different aspects and work together as a prototype for building an AI Copilot that can work with
                    pathologists and be deployed in the medical system. We have provided an example of correction in the
                    main text. Our prompts used in these two pipelines are summarized in Appendix <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#A1"
                        title="Appendix A Prompt list ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">A</span></a>.</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
                <figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span
                            class="ltx_text ltx_font_bold">Algorithm 1</span> </span> Verifier-Corrector Pipeline in
                    TeamPath.</figcaption>
                <div class="ltx_listing ltx_listing">
                    <div class="ltx_listingline" id="alg1.l1">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">1:</span></span><span
                            class="ltx_text ltx_font_bold">Input:</span> Question <math alttext="Q_{M}" class="ltx_Math"
                            display="inline" id="alg1.l1.m1" intent=":literal">
                            <semantics>
                                <msub>
                                    <mi>Q</mi>
                                    <mi>M</mi>
                                </msub>
                                <annotation encoding="application/x-tex">Q_{M}</annotation>
                            </semantics>
                        </math>, pathology image <math alttext="I_{S}" class="ltx_Math" display="inline" id="alg1.l1.m2"
                            intent=":literal">
                            <semantics>
                                <msub>
                                    <mi>I</mi>
                                    <mi>S</mi>
                                </msub>
                                <annotation encoding="application/x-tex">I_{S}</annotation>
                            </semantics>
                        </math>, human answer <math alttext="O_{A}" class="ltx_Math" display="inline" id="alg1.l1.m3"
                            intent=":literal">
                            <semantics>
                                <msub>
                                    <mi>O</mi>
                                    <mi>A</mi>
                                </msub>
                                <annotation encoding="application/x-tex">O_{A}</annotation>
                            </semantics>
                        </math>, reasoning path <math alttext="O_{R}" class="ltx_Math" display="inline" id="alg1.l1.m4"
                            intent=":literal">
                            <semantics>
                                <msub>
                                    <mi>O</mi>
                                    <mi>R</mi>
                                </msub>
                                <annotation encoding="application/x-tex">O_{R}</annotation>
                            </semantics>
                        </math>, verify prompt <math alttext="T_{V}" class="ltx_Math" display="inline" id="alg1.l1.m5"
                            intent=":literal">
                            <semantics>
                                <msub>
                                    <mi>T</mi>
                                    <mi>V</mi>
                                </msub>
                                <annotation encoding="application/x-tex">T_{V}</annotation>
                            </semantics>
                        </math>, correct prompt <math alttext="T_{C}" class="ltx_Math" display="inline" id="alg1.l1.m6"
                            intent=":literal">
                            <semantics>
                                <msub>
                                    <mi>T</mi>
                                    <mi>C</mi>
                                </msub>
                                <annotation encoding="application/x-tex">T_{C}</annotation>
                            </semantics>
                        </math>, number of iteration <math alttext="N" class="ltx_Math" display="inline" id="alg1.l1.m7"
                            intent=":literal">
                            <semantics>
                                <mi>N</mi>
                                <annotation encoding="application/x-tex">N</annotation>
                            </semantics>
                        </math>.

                    </div>
                    <div class="ltx_listingline" id="alg1.l2">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">2:</span></span><span class="ltx_text ltx_font_bold">Helper
                            Models:</span> Verifier <math alttext="\mathcal{M}_{v}" class="ltx_Math" display="inline"
                            id="alg1.l2.m1" intent=":literal">
                            <semantics>
                                <msub>
                                    <mi class="ltx_font_mathcaligraphic">ℳ</mi>
                                    <mi>v</mi>
                                </msub>
                                <annotation encoding="application/x-tex">\mathcal{M}_{v}</annotation>
                            </semantics>
                        </math> (An advanced LMM, such as O4-mini), corrector <math alttext="\mathcal{M}_{c}"
                            class="ltx_Math" display="inline" id="alg1.l2.m2" intent=":literal">
                            <semantics>
                                <msub>
                                    <mi class="ltx_font_mathcaligraphic">ℳ</mi>
                                    <mi>c</mi>
                                </msub>
                                <annotation encoding="application/x-tex">\mathcal{M}_{c}</annotation>
                            </semantics>
                        </math> (An pathology-specific LMM, such as TeamPath with RL finetuning), concatenation function
                        <math alttext="\cdot||\cdot" class="ltx_math_unparsed" display="inline" id="alg1.l2.m3"
                            intent=":literal">
                            <semantics>
                                <mrow>
                                    <mo rspace="0em">⋅</mo>
                                    <mo fence="false" rspace="0.167em" stretchy="false">|</mo>
                                    <mo fence="false" stretchy="false">|</mo>
                                    <mo lspace="0em">⋅</mo>
                                </mrow>
                                <annotation encoding="application/x-tex">\cdot||\cdot</annotation>
                            </semantics>
                        </math>.

                    </div>
                    <div class="ltx_listingline" id="alg1.l3">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">3:</span></span><span
                            class="ltx_text ltx_font_bold">Output:</span> Corrected outputs <math alttext="O_{C}"
                            class="ltx_Math" display="inline" id="alg1.l3.m1" intent=":literal">
                            <semantics>
                                <msub>
                                    <mi>O</mi>
                                    <mi>C</mi>
                                </msub>
                                <annotation encoding="application/x-tex">O_{C}</annotation>
                            </semantics>
                        </math>
                    </div>
                    <div class="ltx_listingline" id="alg1.l4">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">4:</span></span>INIT: initialize all parameters.

                    </div>
                    <div class="ltx_listingline" id="alg1.l5">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">5:</span></span><span class="ltx_text ltx_font_bold">if</span>
                        <math alttext="\mathcal{M}_{v}(T_{V},Q_{M}||O_{R}||O_{A},I_{S})" class="ltx_Math"
                            display="inline" id="alg1.l5.m1" intent=":literal">
                            <semantics>
                                <mrow>
                                    <msub>
                                        <mi class="ltx_font_mathcaligraphic">ℳ</mi>
                                        <mi>v</mi>
                                    </msub>
                                    <mo lspace="0em" rspace="0em">​</mo>
                                    <mrow>
                                        <mo stretchy="false">(</mo>
                                        <msub>
                                            <mi>T</mi>
                                            <mi>V</mi>
                                        </msub>
                                        <mo>,</mo>
                                        <mrow>
                                            <msub>
                                                <mi>Q</mi>
                                                <mi>M</mi>
                                            </msub>
                                            <mo lspace="0em" rspace="0em">​</mo>
                                            <mrow>
                                                <mo stretchy="false">‖</mo>
                                                <msub>
                                                    <mi>O</mi>
                                                    <mi>R</mi>
                                                </msub>
                                                <mo stretchy="false">‖</mo>
                                            </mrow>
                                            <mo lspace="0em" rspace="0em">​</mo>
                                            <msub>
                                                <mi>O</mi>
                                                <mi>A</mi>
                                            </msub>
                                        </mrow>
                                        <mo>,</mo>
                                        <msub>
                                            <mi>I</mi>
                                            <mi>S</mi>
                                        </msub>
                                        <mo stretchy="false">)</mo>
                                    </mrow>
                                </mrow>
                                <annotation encoding="application/x-tex">
                                    \mathcal{M}_{v}(T_{V},Q_{M}||O_{R}||O_{A},I_{S})</annotation>
                            </semantics>
                        </math> is True <span class="ltx_text ltx_font_bold">then</span>
                    </div>
                    <div class="ltx_listingline" id="alg1.l6">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">6:</span></span>  <math alttext="O_{C}=O_{A}" class="ltx_Math"
                            display="inline" id="alg1.l6.m1" intent=":literal">
                            <semantics>
                                <mrow>
                                    <msub>
                                        <mi>O</mi>
                                        <mi>C</mi>
                                    </msub>
                                    <mo>=</mo>
                                    <msub>
                                        <mi>O</mi>
                                        <mi>A</mi>
                                    </msub>
                                </mrow>
                                <annotation encoding="application/x-tex">O_{C}=O_{A}</annotation>
                            </semantics>
                        </math>
                    </div>
                    <div class="ltx_listingline" id="alg1.l7">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">7:</span></span>  Return <math alttext="O_{C}" class="ltx_Math"
                            display="inline" id="alg1.l7.m1" intent=":literal">
                            <semantics>
                                <msub>
                                    <mi>O</mi>
                                    <mi>C</mi>
                                </msub>
                                <annotation encoding="application/x-tex">O_{C}</annotation>
                            </semantics>
                        </math>
                    </div>
                    <div class="ltx_listingline" id="alg1.l8">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">8:</span></span><span class="ltx_text ltx_font_bold">end</span>
                        <span class="ltx_text ltx_font_bold">if</span>
                    </div>
                    <div class="ltx_listingline" id="alg1.l9">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">9:</span></span><span class="ltx_text ltx_font_bold">for</span>
                        <math alttext="i" class="ltx_Math" display="inline" id="alg1.l9.m1" intent=":literal">
                            <semantics>
                                <mi>i</mi>
                                <annotation encoding="application/x-tex">i</annotation>
                            </semantics>
                        </math> in <math alttext="N" class="ltx_Math" display="inline" id="alg1.l9.m2"
                            intent=":literal">
                            <semantics>
                                <mi>N</mi>
                                <annotation encoding="application/x-tex">N</annotation>
                            </semantics>
                        </math> steps <span class="ltx_text ltx_font_bold">do</span>
                    </div>
                    <div class="ltx_listingline" id="alg1.l10">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">10:</span></span>  <math
                            alttext="O_{i},R_{i}=\mathcal{M}_{c}(T_{C},Q_{M}||O_{R}||O_{A},I_{S})" class="ltx_Math"
                            display="inline" id="alg1.l10.m1" intent=":literal">
                            <semantics>
                                <mrow>
                                    <mrow>
                                        <msub>
                                            <mi>O</mi>
                                            <mi>i</mi>
                                        </msub>
                                        <mo>,</mo>
                                        <msub>
                                            <mi>R</mi>
                                            <mi>i</mi>
                                        </msub>
                                    </mrow>
                                    <mo>=</mo>
                                    <mrow>
                                        <msub>
                                            <mi class="ltx_font_mathcaligraphic">ℳ</mi>
                                            <mi>c</mi>
                                        </msub>
                                        <mo lspace="0em" rspace="0em">​</mo>
                                        <mrow>
                                            <mo stretchy="false">(</mo>
                                            <msub>
                                                <mi>T</mi>
                                                <mi>C</mi>
                                            </msub>
                                            <mo>,</mo>
                                            <mrow>
                                                <msub>
                                                    <mi>Q</mi>
                                                    <mi>M</mi>
                                                </msub>
                                                <mo lspace="0em" rspace="0em">​</mo>
                                                <mrow>
                                                    <mo stretchy="false">‖</mo>
                                                    <msub>
                                                        <mi>O</mi>
                                                        <mi>R</mi>
                                                    </msub>
                                                    <mo stretchy="false">‖</mo>
                                                </mrow>
                                                <mo lspace="0em" rspace="0em">​</mo>
                                                <msub>
                                                    <mi>O</mi>
                                                    <mi>A</mi>
                                                </msub>
                                            </mrow>
                                            <mo>,</mo>
                                            <msub>
                                                <mi>I</mi>
                                                <mi>S</mi>
                                            </msub>
                                            <mo stretchy="false">)</mo>
                                        </mrow>
                                    </mrow>
                                </mrow>
                                <annotation encoding="application/x-tex">
                                    O_{i},R_{i}=\mathcal{M}_{c}(T_{C},Q_{M}||O_{R}||O_{A},I_{S})</annotation>
                            </semantics>
                        </math>
                    </div>
                    <div class="ltx_listingline" id="alg1.l11">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">11:</span></span>  <span class="ltx_text ltx_font_bold">if</span>
                        <math alttext="\mathcal{M}_{v}(T_{V},Q_{M}||R_{i}||O_{i},I_{S})" class="ltx_Math"
                            display="inline" id="alg1.l11.m1" intent=":literal">
                            <semantics>
                                <mrow>
                                    <msub>
                                        <mi class="ltx_font_mathcaligraphic">ℳ</mi>
                                        <mi>v</mi>
                                    </msub>
                                    <mo lspace="0em" rspace="0em">​</mo>
                                    <mrow>
                                        <mo stretchy="false">(</mo>
                                        <msub>
                                            <mi>T</mi>
                                            <mi>V</mi>
                                        </msub>
                                        <mo>,</mo>
                                        <mrow>
                                            <msub>
                                                <mi>Q</mi>
                                                <mi>M</mi>
                                            </msub>
                                            <mo lspace="0em" rspace="0em">​</mo>
                                            <mrow>
                                                <mo stretchy="false">‖</mo>
                                                <msub>
                                                    <mi>R</mi>
                                                    <mi>i</mi>
                                                </msub>
                                                <mo stretchy="false">‖</mo>
                                            </mrow>
                                            <mo lspace="0em" rspace="0em">​</mo>
                                            <msub>
                                                <mi>O</mi>
                                                <mi>i</mi>
                                            </msub>
                                        </mrow>
                                        <mo>,</mo>
                                        <msub>
                                            <mi>I</mi>
                                            <mi>S</mi>
                                        </msub>
                                        <mo stretchy="false">)</mo>
                                    </mrow>
                                </mrow>
                                <annotation encoding="application/x-tex">
                                    \mathcal{M}_{v}(T_{V},Q_{M}||R_{i}||O_{i},I_{S})</annotation>
                            </semantics>
                        </math> is True <span class="ltx_text ltx_font_bold">then</span>
                    </div>
                    <div class="ltx_listingline" id="alg1.l12">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">12:</span></span>   <math alttext="O_{C}=O_{i}" class="ltx_Math"
                            display="inline" id="alg1.l12.m1" intent=":literal">
                            <semantics>
                                <mrow>
                                    <msub>
                                        <mi>O</mi>
                                        <mi>C</mi>
                                    </msub>
                                    <mo>=</mo>
                                    <msub>
                                        <mi>O</mi>
                                        <mi>i</mi>
                                    </msub>
                                </mrow>
                                <annotation encoding="application/x-tex">O_{C}=O_{i}</annotation>
                            </semantics>
                        </math>
                    </div>
                    <div class="ltx_listingline" id="alg1.l13">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">13:</span></span>   Return <math alttext="O_{C}" class="ltx_Math"
                            display="inline" id="alg1.l13.m1" intent=":literal">
                            <semantics>
                                <msub>
                                    <mi>O</mi>
                                    <mi>C</mi>
                                </msub>
                                <annotation encoding="application/x-tex">O_{C}</annotation>
                            </semantics>
                        </math>
                    </div>
                    <div class="ltx_listingline" id="alg1.l14">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">14:</span></span>  <span
                            class="ltx_text ltx_font_bold">else</span>
                    </div>
                    <div class="ltx_listingline" id="alg1.l15">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">15:</span></span>   <math alttext="O_{R}=R_{i}" class="ltx_Math"
                            display="inline" id="alg1.l15.m1" intent=":literal">
                            <semantics>
                                <mrow>
                                    <msub>
                                        <mi>O</mi>
                                        <mi>R</mi>
                                    </msub>
                                    <mo>=</mo>
                                    <msub>
                                        <mi>R</mi>
                                        <mi>i</mi>
                                    </msub>
                                </mrow>
                                <annotation encoding="application/x-tex">O_{R}=R_{i}</annotation>
                            </semantics>
                        </math>
                    </div>
                    <div class="ltx_listingline" id="alg1.l16">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">16:</span></span>   <math alttext="O_{A}=O_{i}" class="ltx_Math"
                            display="inline" id="alg1.l16.m1" intent=":literal">
                            <semantics>
                                <mrow>
                                    <msub>
                                        <mi>O</mi>
                                        <mi>A</mi>
                                    </msub>
                                    <mo>=</mo>
                                    <msub>
                                        <mi>O</mi>
                                        <mi>i</mi>
                                    </msub>
                                </mrow>
                                <annotation encoding="application/x-tex">O_{A}=O_{i}</annotation>
                            </semantics>
                        </math>
                    </div>
                    <div class="ltx_listingline" id="alg1.l17">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">17:</span></span>  <span
                            class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">if</span>
                    </div>
                    <div class="ltx_listingline" id="alg1.l18">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">18:</span></span><span class="ltx_text ltx_font_bold">end</span>
                        <span class="ltx_text ltx_font_bold">for</span>
                    </div>
                    <div class="ltx_listingline" id="alg1.l19">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">19:</span></span><math alttext="O_{C}=O_{A}" class="ltx_Math"
                            display="inline" id="alg1.l19.m1" intent=":literal">
                            <semantics>
                                <mrow>
                                    <msub>
                                        <mi>O</mi>
                                        <mi>C</mi>
                                    </msub>
                                    <mo>=</mo>
                                    <msub>
                                        <mi>O</mi>
                                        <mi>A</mi>
                                    </msub>
                                </mrow>
                                <annotation encoding="application/x-tex">O_{C}=O_{A}</annotation>
                            </semantics>
                        </math>
                    </div>
                    <div class="ltx_listingline" id="alg1.l20">
                        <span class="ltx_tag ltx_tag_listingline"><span class="ltx_text"
                                style="font-size:80%;">20:</span></span>Return <math alttext="O_{C}" class="ltx_Math"
                            display="inline" id="alg1.l20.m1" intent=":literal">
                            <semantics>
                                <msub>
                                    <mi>O</mi>
                                    <mi>C</mi>
                                </msub>
                                <annotation encoding="application/x-tex">O_{C}</annotation>
                            </semantics>
                        </math>
                    </div>
                </div>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S4.p20">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">Adapting TeamPath for image summarization and
                        cross-modality generation.</span> To summarize the concepts in histopathology images and further
                    generate image caption, we finetune our base model based on the paired image-caption dataset with
                    the corresponding training set, and we also prepare 3000 samples which are only used for testing,
                    and we utilize Deepseek-R1 <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">guo2025deepseek</span>)</cite> to extract
                    the disease state and tissue source of the testing samples based on their captions. Our finetuning
                    step follows the setting in Instruction-Tuning implemented in Llama-factory. We construct 10
                    different prompts to ask TeamPath for generating the image captions to reduce the bias of prompt
                    information in the training process.</p><button class="sr-only button" style="display: none;">Report
                    issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p21">
                <p class="ltx_p">To perform the cross-modality generation task, we also finetune our base model based on
                    the paired image-transcriptomic profile dataset with the corresponding training datasets. We select
                    sequence data that comes from different batches and resources, but the same tissue/disease, to build
                    a testing dataset. To transfer the information in gene expression space to text space, we first rank
                    the genes of each spot based on their expression profiles and select the top 100 genes to formulate
                    them in natural language. We then train a linear regressor that takes the natural language
                    information as inputs and original gene expression profiles as outputs based on the training
                    dataset, which finally gives us a method to decode the language information back to gene expression
                    levels. We finetune our base model with the same approach used in image summarization and also
                    construct 10 different prompts to ask TeamPath for generating gene expression profiles.</p><button
                    class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p22">
                <p class="ltx_p">The prompts used in this section can also be found in Appendix <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#A1"
                        title="Appendix A Prompt list ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">A</span></a>.</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p23">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">Evaluations.</span> In this manuscript, we
                    consider task-specific evaluation <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">pedregosa2011scikit</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">virtanen2020scipy</span>)</cite> and
                    follow the settings from previous works with shared tasks.</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p24">
                <p class="ltx_p">For the evaluation of Path VQA and Human-AI collaboration tasks, we utilize accuracy as
                    a metric. The generated answer should be precisely matched with the provided answer. A higher
                    accuracy represents a better method.</p><button class="sr-only button" style="display: none;">Report
                    issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p25">
                <p class="ltx_p">For the evaluation of the image caption summarization task, we utilize several metrics
                    that can measure the similarity between the generated text and the provided text. These metrics
                    include BLEU, ROUGE-1, ROUGE-2, ROUGE-L, BERT score, and MEDCON <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">papineni2002bleu</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">lin2004rouge</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">zhangbertscore</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">jain1radgraph</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">yim2023aci</span>)</cite>, supported by a
                    recent publication <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">van2024adapted</span>)</cite>. We also
                    consider the average score across these metrics. Here are the descriptions:</p><button
                    class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p26">
                <ul class="ltx_itemize" id="S4.I1">
                    <li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
                        <span class="ltx_tag ltx_tag_item">•</span>
                        <div class="ltx_para" id="S4.I1.i1.p1">
                            <p class="ltx_p">BLEU: The BiLingual Evaluation Understudy (BLEU) score evaluates the
                                quality of generated text by breaking both the generated output and the reference text
                                into n-grams, then comparing the overlap between the two sets. The score ranges from 0
                                to 1 and is typically scaled to a range of 0 to 100, with higher values indicating
                                better model performance.</p><button class="sr-only button"
                                style="display: none;">Report issue for preceding element</button>
                        </div>
                    </li>
                    <li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
                        <span class="ltx_tag ltx_tag_item">•</span>
                        <div class="ltx_para" id="S4.I1.i2.p1">
                            <p class="ltx_p">ROUGE: The Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score
                                assesses text quality by computing the F1 score from n-gram overlaps between the
                                generated text and the reference text. In this framework, n-grams from the generated
                                text are treated as predictions, while those from the reference text serve as labels.
                                Precision, recall, and the F1 score are calculated using the counts of matching n-grams
                                and their lengths. ROUGE-1 measures unigram overlap, ROUGE-2 measures bigram overlap,
                                and ROUGE-L measures the longest common subsequence. The score ranges from 0 to 1 and is
                                typically scaled to a range of 0 to 100, with higher values indicating better model
                                performance.</p><button class="sr-only button" style="display: none;">Report issue for
                                preceding element</button>
                        </div>
                    </li>
                    <li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
                        <span class="ltx_tag ltx_tag_item">•</span>
                        <div class="ltx_para" id="S4.I1.i3.p1">
                            <p class="ltx_p">BERT: The Bidirectional Encoder Representations from Transformers (BERT)
                                model is pre-trained on large-scale text corpora for language understanding and excels
                                at producing rich text representations. The BERTScore metric leverages this capability
                                by measuring the similarity between embeddings of the generated text and the reference
                                text. The score ranges from 0 to 1 and is typically scaled to a range of 0 to 100, with
                                higher values indicating better model performance.</p><button class="sr-only button"
                                style="display: none;">Report issue for preceding element</button>
                        </div>
                    </li>
                    <li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
                        <span class="ltx_tag ltx_tag_item">•</span>
                        <div class="ltx_para" id="S4.I1.i4.p1">
                            <p class="ltx_p">MEDCON: MEDCON limits the recognized concepts and entities to the semantic
                                groups defined in QuickUMLS <cite class="ltx_cite ltx_citemacro_cite">(<span
                                        class="ltx_ref ltx_missing_citation ltx_ref_self">soldaini2016quickumls</span>)</cite>,
                                including Anatomy, Chemicals, Drugs, Device, Disorders, Genes, Molecular Sequences,
                                Phenomena, and Physiology. These concepts are extracted from both the generated text and
                                the reference text, and the F1 score is calculated based on the overlap between the two
                                sets. The score ranges from 0 to 1 and is typically scaled to a range of 0 to 100, with
                                higher values indicating better model performance.</p><button class="sr-only button"
                                style="display: none;">Report issue for preceding element</button>
                        </div>
                    </li>
                </ul>
            </div>
            <div class="ltx_para" id="S4.p27">
                <p class="ltx_p">A higher score of these metrics represents a better method.</p><button
                    class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p28">
                <p class="ltx_p">For the evaluation of the cross-modality generation task, we consider spot-level
                    Pearson Correlation Coefficient (SPCC), gene-level PCC (GPCC), and Mean Squared Error (MSE) as
                    metrics. Higher SPCC and GPCC scores represent a better method, while a lower MSE score represents a
                    better method. These metrics are computed between generated gene expression profiles and observed
                    gene expression profiles.</p><button class="sr-only button" style="display: none;">Report issue for
                    preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p29">
                <p class="ltx_p"><span class="ltx_text ltx_font_bold">Baselines.</span> Our baseline methods cover
                    current state-of-the-art (SOTA) open-source LMMs based on the open source movement in scientific
                    research and the powerful influence of open source models. Moreover, there are a few powerful
                    closed-source models focusing on digital histopathology. We apply the access to PathChat <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">lu2024multimodal</span>)</cite> but have
                    not received the authorization. These models include MedGemma-4B, Qwen2.5VL-3B, Qwen2.5VL-7B,
                    MedVLThinker-7B, InternVL3-8B, PathGen-LLaVA-13B, and Patho-R1 (7B). MedGemma-4B is an open-source
                    VLM released by Google based on finetuning Gemma with multimodal medical data. Qwen2.5VL-3B and
                    Qwen2.5VL-7B are open-source VLMs from the Qwen team, Alibaba Cloud. They are trained with
                    multimodal data in the general domain. InternVL3-8B is an open-source VLM released by OpenGVLab, and
                    it is also trained with multimodal data from the general domain. For pathology-specific models, we
                    consider PathGen-LLaVA-13B <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">sunpathgen</span>)</cite>, which is
                    finetuned based on LLAVA 13B <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">liu2023visual</span>)</cite> with
                    instruction data from PathGen; as well as Patho-R1, which has a pathology-specific image encoder and
                    is finetuned based on Qwen2.5VL-3B with reasoning data.</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S4.p30">
                <p class="ltx_p">For the cross-modality generation task, we also consider a task-specific baseline
                    method, known as Cell2Sentence (1B) <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">levine2024cell2sentence</span>)</cite>.
                    Cell2Sentence is finetuned with instructions and single-cell transcriptomic data from atlas-level
                    datasets based on Pythia. This model can generate cells based on instructions.</p><button
                    class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
        </section>
        <section class="ltx_section" id="S5" lang="en">
            <h2 class="ltx_title ltx_title_section">
                <span class="ltx_tag ltx_tag_section">5 </span>Code and Data Availability
            </h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S5.p1">
                <p class="ltx_p">We utilize NCSA, YCRC, and TokyoU HPC platforms to perform experiments. To train
                    TeamPath, we utilize 32 NVIDIA H100 cores and 8 NVIDIA H200 cores for 24 hours. The CPU memory upper
                    bound is 80GB. The codes can be found in <a class="ltx_ref ltx_url ltx_font_typewriter"
                        href="https://github.com/HelloWorldLTY/TeamPath"
                        title="">https://github.com/HelloWorldLTY/TeamPath</a>, and the license is the MIT license.</p>
                <button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="S5.p2">
                <p class="ltx_p">The information on the datasets used in this manuscript can be found in Supplementary
                    File 1. To access TCGA data, an authorized account is required. To protect personal privacy, we will
                    not release experts’ answers.</p><button class="sr-only button" style="display: none;">Report issue
                    for preceding element</button>
            </div>
        </section>
        <section class="ltx_section" id="S6" lang="en">
            <h2 class="ltx_title ltx_title_section">
                <span class="ltx_tag ltx_tag_section">6 </span>Acknowledgments
            </h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S6.p1">
                <p class="ltx_p">We thank Mr. Tong Ding for his suggestion on model training and task selection.</p>
                <button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
        </section>
        <section class="ltx_section" id="S7" lang="en">
            <h2 class="ltx_title ltx_title_section">
                <span class="ltx_tag ltx_tag_section">7 </span>Author Contributions
            </h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S7.p1">
                <p class="ltx_p">T.L. and W.X. designed this study. T.L., W.X., and H.Q. ran all the experiments. H.W.,
                    P.H., M.D. performed human evaluation. All authors involved in writing and reviewing. H.Z.
                    supervised this study.</p><button class="sr-only button" style="display: none;">Report issue for
                    preceding element</button>
            </div>
        </section>
        <section class="ltx_section" id="S8" lang="en">
            <h2 class="ltx_title ltx_title_section">
                <span class="ltx_tag ltx_tag_section">8 </span>Institutional Review Board (IRB) Approval.
            </h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="S8.p1">
                <p class="ltx_p">This project has received approval from Yale IRB, with project number 2000039055.</p>
                <button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_pagination ltx_role_newpage"></div>
        </section>
        <section class="ltx_appendix" id="A1" lang="en">
            <h2 class="ltx_title ltx_title_appendix">
                <span class="ltx_tag ltx_tag_appendix">Appendix A </span>Prompt list
            </h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="A1.p1">
                <p class="ltx_p">The prompt used for the Pathology VQA is:</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <section class="ltx_paragraph" id="A1.SS0.SSS0.Px1">
                <h3 class="ltx_title ltx_title_paragraph">Your task:
                    1. Think through the question step by step, enclose your reasoning process in
                    &lt;think&gt;…&lt;/think&gt; tags.
                    2. Then provide the correct single-letter choice (A, B, C, D,…) inside
                    &lt;answer&gt;…&lt;/answer&gt; tags.
                    3. No extra information or text outside of these tags.
                    <br class="ltx_break">
                </h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
                <div class="ltx_para" id="A1.SS0.SSS0.Px1.p1">
                    <p class="ltx_p">The prompt used for the self-verifier is:</p><button class="sr-only button"
                        style="display: none;">Report issue for preceding element</button>
                </div>
            </section>
            <section class="ltx_paragraph" id="A1.SS0.SSS0.Px2">
                <h3 class="ltx_title ltx_title_paragraph">You are an expert in pathology. You are given a QUESTION and a
                    PROPOSED SOLUTION. Your job is to:
                    1. Break down each component of the proposed solution.
                    2. Think step by step to verify if the proposed solution is correct given the question and the
                    figure.
                    3. Write a line of the form "The proposed solution is correct" or "The proposed solution is
                    incorrect" at the end of your response based on your analysis.
                    QUESTION: question.
                    PROPOSED SOLUTION: solution.
                    <br class="ltx_break">
                </h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
                <div class="ltx_para" id="A1.SS0.SSS0.Px2.p1">
                    <p class="ltx_p">The prompt used for the self-corrector is:</p><button class="sr-only button"
                        style="display: none;">Report issue for preceding element</button>
                </div>
            </section>
            <section class="ltx_paragraph" id="A1.SS0.SSS0.Px3">
                <h3 class="ltx_title ltx_title_paragraph">You are also given a question and an analysis for the
                    question. Your job is to outline your step-by-step thought process for deriving a correct solution
                    and also write down the correct solution. Using this format: &lt;think&gt; Your step-by-step
                    reasoning of the question and solution &lt;<math alttext="/" class="ltx_Math" display="inline"
                        id="A1.SS0.SSS0.Px3.m1" intent=":literal">
                        <semantics>
                            <mo>/</mo>
                            <annotation encoding="application/x-tex">/</annotation>
                        </semantics>
                    </math>think&gt;&lt;answer&gt; Your final answer &lt;<math alttext="/" class="ltx_Math"
                        display="inline" id="A1.SS0.SSS0.Px3.m2" intent=":literal">
                        <semantics>
                            <mo>/</mo>
                            <annotation encoding="application/x-tex">/</annotation>
                        </semantics>
                    </math>answer&gt;
                    Question: question
                    Solution: out_verifier.
                    <br class="ltx_break">
                </h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
                <div class="ltx_para" id="A1.SS0.SSS0.Px3.p1">
                    <p class="ltx_p">The prompt used for the reason corrector is:</p><button class="sr-only button"
                        style="display: none;">Report issue for preceding element</button>
                </div>
            </section>
            <section class="ltx_paragraph" id="A1.SS0.SSS0.Px4">
                <h3 class="ltx_title ltx_title_paragraph">You are given QUESTION, REASON, and SOLUTION. Your task is to
                    correct the REASON and SOLUTION.
                    QUESTION: question.
                    SOLUTION: solution.
                    REASON: reason
                    The REASON is WRONG. Your solution:
                    <br class="ltx_break">
                </h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
                <div class="ltx_para" id="A1.SS0.SSS0.Px4.p1">
                    <p class="ltx_p">The prompts used for training TeamPath for caption summary include:</p><button
                        class="sr-only button" style="display: none;">Report issue for preceding element</button>
                </div>
            </section>
            <section class="ltx_paragraph" id="A1.SS0.SSS0.Px5">
                <h3 class="ltx_title ltx_title_paragraph">Provide a concise pathological summary of the tissue shown in
                    this histopathology image, highlighting any abnormal cellular or structural features in one
                    paragraph.
                    Based on the visual characteristics in this image, summarize the likely histological diagnosis and
                    key indicators leading to it in one paragraph.
                    Describe the main histopathological patterns visible in this image and summarize what they suggest
                    about the tissue state in one paragraph.
                    Summarize the key morphological findings in this histopathology image, including any signs of
                    malignancy, inflammation, or necrosis in one paragraph.
                    Generate a pathology report-style summary based solely on this histological section, mentioning
                    tissue type, grade, and diagnostic clues in one paragraph.
                    Briefly summarize the clinical implications of the abnormalities visible in this histopathology
                    image in one paragraph.
                    From this histopathology image, extract and summarize the most diagnostically relevant features in
                    one paragraph.
                    Identify and summarize any histopathological hallmarks (e.g., mitotic figures, glandular formation,
                    stromal invasion) present in the image in one paragraph.
                    Write a summary suitable for a pathology trainee explaining what this histopathology image
                    represents and why in one paragraph.
                    Provide an expert-level summary of the pathological findings in this histopathology image, including
                    your confidence in the assessment in one paragraph.
                    <br class="ltx_break">
                </h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
                <div class="ltx_para" id="A1.SS0.SSS0.Px5.p1">
                    <p class="ltx_p">The prompts used for training TeamPath for cross-modality generation (using IDC as
                        an example) include:</p><button class="sr-only button" style="display: none;">Report issue for
                        preceding element</button>
                </div>
            </section>
            <section class="ltx_paragraph" id="A1.SS0.SSS0.Px6">
                <h3 class="ltx_title ltx_title_paragraph">Generate a list of 100 genes in order of descending expression
                    from one spot shown in the histopathology image in IDC disease. Cell sentence:,
                    Produce a list of 100 gene names in descending order of expression which represent the expressed
                    genes from one spot shown in the histopathology image in IDC disease. Cell sentence:,
                    Create a ranked list of 100 genes in decreasing order of expression from one spot shown in the
                    histopathology image in IDC disease. Cell sentence:,
                    List the top 100 expressed genes from one spot shown in the histopathology image in IDC disease.
                    Cell sentence:,
                    Identify the highest expressed 100 genes in decreasing order of expression from one spot shown in
                    the histopathology image in IDC disease. Cell sentence:,
                    Enumerate a list of 100 genes in descending order of expression from one spot shown in the
                    histopathology image in IDC disease. Cell sentence:,
                    Compile a descending order list of 100 expressed genes from one spot shown in the histopathology
                    image in IDC disease. Cell sentence:,
                    Present a sequence of 100 genes ordered by decreasing expression level from one spot shown in the
                    histopathology image in IDC disease. Cell sentence:,
                    Generate an ordered list of 100 genes by decreasing expression level from one spot shown in the
                    histopathology image in IDC disease. Cell sentence:,
                    Assemble a list of 100 genes from highest to lowest expression from one spot shown in the
                    histopathology image in IDC disease. Cell sentence:
                    <br class="ltx_break">
                </h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </section>
        </section>
        <section class="ltx_appendix" id="A2" lang="en">
            <h2 class="ltx_title ltx_title_appendix">
                <span class="ltx_tag ltx_tag_appendix">Appendix B </span>SFT vs RL: Comparison for training strategies.
            </h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="A2.p1">
                <p class="ltx_p">How to train a mature reasoning model has always been a controversial topic, as there
                    exist several different strategies and their performances and ranks might vary under different task
                    settings or experiment settings <cite class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">chu2025sft</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">wang2025reinforcement</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">liu2025part</span>)</cite>. Meanwhile,
                    this kind of discussion has not been investigated in training a large reasoning model for
                    histopathology analysis, and thus, we consider several different approaches to provide an empirical
                    analysis to select and interpret the best combination, which might inspire future directions or
                    different researchers.</p><button class="sr-only button" style="display: none;">Report issue for
                    preceding element</button>
            </div>
            <div class="ltx_para" id="A2.p2">
                <p class="ltx_p">We conduct these experiments based on different base models as well as training
                    strategies. Our base models include Qwen2.5VL-7B, which does not contain domain-specific knowledge
                    and Patho-R1-7B, which contains domain-specific knowledge. We also consider different training
                    strategies, including RL (GRPO), RL (DAPO), SFT, and SFT<math alttext="+" class="ltx_Math"
                        display="inline" id="A2.p2.m1" intent=":literal">
                        <semantics>
                            <mo>+</mo>
                            <annotation encoding="application/x-tex">+</annotation>
                        </semantics>
                    </math>RL (GRPO). Extended Data Figures <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#A4.F3"
                        title="Extended Data Fig. 3 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">3</span></a> (a) and (b) show that GRPO can achieve a more
                    obvious score improvement while DAPO cannot make an improvement, which implies that a mixture of
                    tricks does not contribute to training a multi-modal pathology reasoning model. Extended Data
                    Figures <a class="ltx_ref" href="https://arxiv.org/html/2511.17652v1#A4.F3"
                        title="Extended Data Fig. 3 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">3</span></a> (c) and (d) show that it is important to select a
                    base model with domain knowledge for training, and performing SFT<math alttext="+" class="ltx_Math"
                        display="inline" id="A2.p2.m2" intent=":literal">
                        <semantics>
                            <mo>+</mo>
                            <annotation encoding="application/x-tex">+</annotation>
                        </semantics>
                    </math>RL or direct SFT settings does not benefit this task. Therefore, our optimal choice to build
                    TeamPath for pathology VQA is Patho-R1-7B+RL (GRPO).</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_para" id="A2.p3">
                <p class="ltx_p">In conclusion, our results showcase that it is important to select a good model with
                    domain knowledge to perform training, and for LMMs that can already possess domain knowledge,
                    directly training them using RL policies can enhance their generalization capabilities without
                    requiring specialized SFT training (also known as cold-start training). Our important findings also
                    align with relevant research across different fields <cite
                        class="ltx_cite ltx_citemacro_cite">(<span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">chen2025sft</span>, <span
                            class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2025policy</span>)</cite>, which
                    indirectly validates the reliability of our conclusions.</p><button class="sr-only button"
                    style="display: none;">Report issue for preceding element</button>
            </div>
        </section>
        <section class="ltx_appendix" id="A3" lang="en">
            <h2 class="ltx_title ltx_title_appendix">
                <span class="ltx_tag ltx_tag_appendix">Appendix C </span>Studies for training data ablation.
            </h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_para" id="A3.p1">
                <p class="ltx_p">We also investigate if incorporating more diverse data could help TeamPath for
                    generating a better reasoning path or not. To examine it, we compare the results between only using
                    multi-choice VQA (mc VQA) data and using both multi-choice VQA and open-ended VQA (full VQA) data.
                    Based on our evaluation results shown in Extended Data Figure <a class="ltx_ref"
                        href="https://arxiv.org/html/2511.17652v1#A4.F4"
                        title="Extended Data Fig. 4 ‣ Appendix D Supplementary figures ‣ TeamPath: Building MultiModal Pathology Experts with Reasoning AI Copilots"><span
                            class="ltx_text ltx_ref_tag">4</span></a> with validation from the PathMMU dataset, using
                    full VQA data cannot boost TeamPath’s performances in generalizing the results for solving questions
                    in the PathMMU dataset. Therefore, our optimal setting only takes mc VQA for RL training. Details of
                    the reward design for these two different types of data are explained in the Method section.</p>
                <button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            </div>
            <div class="ltx_pagination ltx_role_newpage"></div>
        </section>
        <section class="ltx_appendix" id="A4" lang="en">
            <h2 class="ltx_title ltx_title_appendix">
                <span class="ltx_tag ltx_tag_appendix">Appendix D </span>Supplementary figures
            </h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <figure class="ltx_figure" id="A4.F1"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_landscape" height="585" id="A4.F1.g1" src="x7.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Extended Data Fig. 1:
                    </span>A flowchart of data-preprocessing used to train TeamPath.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_pagination ltx_role_newpage"></div>
            <figure class="ltx_figure" id="A4.F2"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_square" height="836" id="A4.F2.g1" src="x8.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Extended Data Fig. 2:
                    </span>Case study (topic: lipoblast, which is a protein found in the presynaptic vesicles of neurons
                    and neuroendocrine cells that plays a role in synaptic transmission) based on the outputs from
                    different models. We highlight the correct information with green text and incorrect information
                    with red text. For the models with errors, we consider two cases. The first case is a wrong answer,
                    the second case is a confused reasoning path.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_pagination ltx_role_newpage"></div>
            <figure class="ltx_figure" id="A4.F3"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_landscape" height="383" id="A4.F3.g1" src="x9.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Extended Data Fig. 3:
                    </span>Training strategies optimization with different settings. The results are evaluated based on
                    the PathMMU dataset. (a) Accuracy across different categories based on the base model and different
                    RL strategies. (b) Accuracy and rank across different categories based on the base model and
                    different RL strategies. (c) Accuracy across different categories based on different base models and
                    different RL/SFT strategies. (d) Accuracy and rank across different categories based on different
                    base models and different RL/SFT strategies.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_pagination ltx_role_newpage"></div>
            <figure class="ltx_figure" id="A4.F4"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_landscape" height="456" id="A4.F4.g1" src="x10.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Extended Data Fig. 4:
                    </span>Comparisons for the PathMMU VQA question set with different training data. The metric is
                    accuracy.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_pagination ltx_role_newpage"></div>
            <figure class="ltx_figure" id="A4.F5"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_landscape" height="210" id="A4.F5.g1" src="x11.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Extended Data Fig. 5:
                    </span>An example of using TeamPath to correct the reasoning path from pathologists.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_pagination ltx_role_newpage"></div>
            <figure class="ltx_figure" id="A4.F6"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_landscape" height="596" id="A4.F6.g1" src="x12.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Extended Data Fig. 6:
                    </span>Ablation studies of using different models as verifiers.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_pagination ltx_role_newpage"></div>
            <figure class="ltx_figure" id="A4.F7"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_landscape" height="223" id="A4.F7.g1" src="x13.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Extended Data Fig. 7:
                    </span>Examples of model outputs for caption summary tasks. We highlight both correct and incorrect
                    information.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_pagination ltx_role_newpage"></div>
            <figure class="ltx_figure" id="A4.F8"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_portrait" height="955" id="A4.F8.g1" src="x14.png"
                    width="664">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Extended Data Fig. 8:
                    </span>Extended analyses of spatial transcriptomic generation. (a) GPCC across different methods
                    based on the brain tissue. (b) GPCC across different methods based on the IDC sample. (c) Comparison
                    between finetuned Qwen2.5VL-7B and TeamPath based on the brain tissue. (d) Comparison between
                    finetuned Qwen2.5VL-7B and TeamPath based on the IDC sample.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
            <div class="ltx_pagination ltx_role_newpage"></div>
            <figure class="ltx_figure" id="A4.F9"><img alt="Refer to caption"
                    class="ltx_graphics ltx_centering ltx_img_landscape" height="345" id="A4.F9.g1" src="x15.png"
                    width="830">
                <figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Extended Data Fig. 9:
                    </span>A case study of TeamPath output for pathology VQA with an incorrect reasoning path but a
                    correct answer.</figcaption>
            </figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
        </section>
    </article>
</div>